{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this Jupyter Notebook is to figure out how to organize and convert data and metadata from Alan Linde.\n",
    "\n",
    "The waveform data should all end up in the DAYS directory in a BUD archive.\n",
    "\n",
    "So far I have only looked at the early-data, which are in REFTEK/PASSCAL-SEGY format consisting of a 240-byte trce header following by a trace, according to Bruce Beaudoin. These trace files seem to be unreadable by ObsPy, but perhaps a help request to the listserv can lead to success. I think I tried converting them with rt2ms also and that failed. I possibly need a much older version of rt2ms.\n",
    "\n",
    "The new directory is basically a place to play with data, e.g. extract *tar.Z files.\n",
    "\n",
    "Hopefully a lot more data are in the Q330 directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libseisGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPDIR = '/Users/thompsong/calipso_data'\n",
    "NEWDIR = os.path.join(TOPDIR, 'new')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. READ DATA FROM THE early-data/bh? DIRECTORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Process early-data/bh?/*.sac\n",
    "I accidentally moved or deleted these after they were combined into the BUD archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'early-data', 'bh?'))\n",
    "filematch = '*.sac'\n",
    "\n",
    "libseisGT.process_wfdirs(wfdirs, filematch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Process early-data/bh?/DT*.???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'early-data', 'bh?'))\n",
    "filematch = 'DT*.???'\n",
    "\n",
    "libseisGT.process_wfdirs(wfdirs, filematch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Process early-data/bh?/*LH?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'early-data', 'bh?'))\n",
    "filematch = '*LH?.'\n",
    "\n",
    "libseisGT.process_wfdirs(wfdirs, filematch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Process early-data/bh5/*_folder/DT*.???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'early-data', 'bh5', '*_folder'))\n",
    "filematch = 'DT*.???'\n",
    "\n",
    "libseisGT.process_wfdirs(wfdirs, filematch)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PROCESSING *TAR.Z FILES IN early-data/bh5\n",
    "\n",
    "## 2.1 Try to uncompress *tar.Z files (JUST 2 FOR NOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'early-data', 'bh?'))\n",
    "for wfdir in wfdirs:\n",
    "    print('Processing %s' % wfdir)\n",
    "    compressedfiles = glob.glob(os.path.join(wfdir, '*.tar.Z'))\n",
    "    for compressedfile in compressedfiles[0:2]:\n",
    "        compressedfileroot = os.path.basename(compressedfile).replace('.tar.Z','')\n",
    "        decompressDir = os.path.join(NEWDIR, compressedfileroot)\n",
    "        decompressFile(compressedfile, decompressDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Try to read a REFTEK/PASSCAL/SEG-Y file from an uncompressed *TAR.Z file\n",
    "\n",
    "### 2.2.1 Using ObsPy blindly\n",
    "\n",
    "TypeError: Unknown format for file /Users/thompsong/calipso_data/new/gerstr.161/03.161.09.04.50.7089.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGYFILE = '/Users/thompsong/calipso_data/new/gerstr.161/03.161.09.04.50.7089.1'\n",
    "#SEGYFILE2 = '/Users/thompsong/calipso_data/new/gerstr.119/03.119.14.13.50.7089.1'\n",
    "st = read(SEGYFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Force ObsPy to treat it as SEGY format with big-endian\n",
    "\n",
    "SEGYError: Unable to determine the endianness of the file. Please specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = read(SEGYFILE, 'SEGY', endian='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Use _read_segy\n",
    "\n",
    "SEGYError: Unable to determine the endianness of the file. Please specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.io.segy.segy import _read_segy\n",
    "segy = _read_segy(SEGYFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Use iread_segy\n",
    "\n",
    "SEGYError: Unable to determine the endianness of the file. Please specify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.io.segy.segy import iread_segy\n",
    "for tr in iread_segy(SEGYFILE):\n",
    "    # Each Trace's stats attribute will have references to the file\n",
    "    # headers and some more information.\n",
    "    tf = tr.stats.segy.textual_file_header\n",
    "    bf = tr.stats.segy.binary_file_header\n",
    "    tfe = tr.stats.segy.textual_file_header_encoding\n",
    "    de = tr.stats.segy.data_encoding\n",
    "    e = tr.stats.segy.endian\n",
    "    # Also do something meaningful with each Trace.\n",
    "    print(int(tr.data.sum() * 1E9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Read as an SEGYTrace object with ObsPy\n",
    "\n",
    "AttributeError: 'str' object has no attribute 'fileno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.io.segy.segy import SEGYTrace\n",
    "sgtrace = SEGYTrace(file=SEGYFILE)\n",
    "sgtrace._read_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Read as a Seismic Unix object with ObsPy\n",
    "\n",
    "ValueError: hour must be in 0..23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.io.segy.segy import iread_su\n",
    "for tr in iread_su(SEGYFILE, endian='big'):\n",
    "    print(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 Reading as 4-byte integer\n",
    "\n",
    "SEG-Y is a big-endian format, which I think can be read as '>i' as '<i' is little-endian. However, there are multiple formats: \n",
    "- 4-byte IBM float\n",
    "- 4-byte 2s-complement integer\n",
    "- 2-byte 2s-complement integer\n",
    "- 4-byte fixed-point with gain\n",
    "- 4-byte IEEE float\n",
    "- 1-byte 2s-complement integer\n",
    "\n",
    "See page 6 of https://seg.org/Portals/0/SEG/News%20and%20Resources/Technical%20Standards/seg_y_rev1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from obspy.core import Trace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fin = open(\"/Users/thompsong/calipso_data/new/gerstr.119/03.119.14.13.50.7089.1\", \"rb\")\n",
    "#header = fin.read(228)\n",
    "linetraceno = struct.unpack('>i', fin.read(4)) # 0-3\n",
    "reeltraceno = struct.unpack('>i', fin.read(4)) # 4-7\n",
    "fieldrecordno = struct.unpack('>i', fin.read(4)) # 8-11\n",
    "fieldtraceno = struct.unpack('>i', fin.read(4)) # 12-15\n",
    "energysourcepointno = struct.unpack('>i', fin.read(4)) # 16-19\n",
    "ensembleno = struct.unpack('>i', fin.read(4)) # 20-23\n",
    "traceno = struct.unpack('>i', fin.read(4)) # 24-27\n",
    "traceidcode = fin.read(2) # 28-29\n",
    "crap = fin.read(4) # 30-33\n",
    "datause = fin.read(2) # 34-35\n",
    "crap2 = fin.read(120) # 36-155\n",
    "year = fin.read(2)\n",
    "doy = fin.read(2) # 158-159\n",
    "crap3 = fin.read(81) # 160-240\n",
    "print(year, doy)\n",
    "print(datause)\n",
    "print(linetraceno, reeltraceno, fieldrecordno)\n",
    "y = []\n",
    "error_flag = False\n",
    "while not error_flag:\n",
    "    try:\n",
    "        y.append(struct.unpack('>i', fin.read(4))) # <i is little-endian, I think >i is big-endian. Intel chips are little endian\n",
    "    except:\n",
    "        error_flag = True\n",
    "fin.close()\n",
    "\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PROCESSING Q330 DATA\n",
    "\n",
    "## 3.1 Process data from Q330data/TR\n",
    "\n",
    "The current problem here is that the Q330data directories contain data not just across a few days, but across years. Need to somehow create an wfdisc-like dataframe index that works day-by-day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'Q330data', 'TR'))\n",
    "filematch = 'TR*.???'\n",
    "\n",
    "libseisGT.process_wfdirs(wfdirs, filematch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Process data from Q330data/O1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station = 'O1'\n",
    "put_away = False\n",
    "#wfdirs = glob.glob(os.path.join(TOPDIR, 'Q330data', station, '2005'))\n",
    "wfdirs = glob.glob(os.path.join(TOPDIR, 'Q330data', station, '2003'))                                \n",
    "filematch = '%s_*' % station\n",
    "\n",
    "libseisGT.process_wfdirs(wfdirs, filematch, put_away) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the following trace from the code above:\n",
    "    QT.429.O1.BHZ | 2005-01-02T15:38:44.388396Z - 2006-01-01T05:35:36.268396Z | 50.0 Hz, 1570670595 samples\n",
    "OK, I need to walk through the wfdisc dataframe and split it into days. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading and plotting a BUD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDDIR = os.path.join(TOPDIR, 'DAYS')\n",
    "st = libseisGT.BUD_load_day(BUDDIR, 2005, 167)\n",
    "if st:\n",
    "    st.plot(equal_scale=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
