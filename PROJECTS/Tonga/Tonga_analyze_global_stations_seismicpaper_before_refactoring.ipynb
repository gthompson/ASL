{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Inspired by my analysis of Miami Lakes Rboom data to measure the pressure pulse from the Tonga eruption an beamform back to the source, I began drinking in global barometric and infrasound data from IRIS (and Shake.net). Steve then took my measurements and began collating a table of reduced pressure versus other eruptions. This then mainfested an invite from Zhigang Peng to collaborate on a Tonga paper to look at all waves emanating from this eruption.\n",
    "\n",
    "While I am focusing on that paper currently, this notebook has lots of earlier work, and will later be expanded for my own conference and journal papers (and one I am co-authoring with Steve).\n",
    "\n",
    "Glenn Thompson, Jan - Feb 2022\n",
    "\n",
    "# 1. Functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, obspy\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "LIBpath = os.path.join( os.getenv('HOME'),'src','kitchensinkGT', 'LIB')\n",
    "sys.path.append(LIBpath)\n",
    "from libseisGT import inventory2traceid, get_FDSN_inventory, clean_trace, \\\n",
    "    attach_station_coordinates_from_inventory\n",
    "from obspy.clients.fdsn import Client\n",
    "#from obspy.core.util import AttribDict\n",
    "from obspy.geodetics import locations2degrees, degrees2kilometers, kilometers2degrees\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def get_fdsn_identifier(fdsnURL):\n",
    "    prepend=''\n",
    "    if 'iris' in fdsnURL:\n",
    "        prepend='iris_'\n",
    "    if 'shake' in fdsnURL:\n",
    "        prepend='rboom_'\n",
    "    if 'geonet' in fdsnURL:\n",
    "        prepend='nz_'  \n",
    "    return prepend\n",
    "\n",
    "def get_inventory_and_waveforms(fdsnClient, searchRadiusDeg, olat, olon, startt, endt, chanstring, data_root, overwrite=False, network='*', station='*', location='*'):\n",
    "    fdsnClient = Client(fdsnURL)  \n",
    "    if not os.path.isdir(data_root):\n",
    "        print('No such directory %s' % data_root)\n",
    "        return None, None\n",
    "    \n",
    "    # STEP 1 - FIND STATIONS BY REQUESTING AN INVENTORY\n",
    "    prepend = get_fdsn_identifier(fdsnURL)\n",
    "    stationXmlFile = os.path.join(data_root, '%s%s_within_%.0f_degrees.xml' % (prepend, chanstring, searchRadiusDeg))\n",
    "    mseedfile = stationXmlFile.replace('.xml','.mseed')\n",
    "    print(stationXmlFile, mseedfile)\n",
    "    \n",
    "    if os.path.exists(stationXmlFile) and overwrite==False:\n",
    "        inv = obspy.read_inventory(stationXmlFile)\n",
    "    else:\n",
    "        inv = get_FDSN_inventory(fdsnClient, startt, stationXmlFile, network, olat, olon, \\\n",
    "            searchRadiusDeg, 0, endt - startt, station = station, channel = chanstring ) # get all low rate, outside barometers\n",
    "    trace_ids = inventory2traceid(inv)\n",
    "    #print(trace_ids)\n",
    "    \n",
    "    # STEP 2 - LOAD CORRESPONDING WAVEFORM DATA\n",
    "    if os.path.exists(mseedfile) and overwrite==False:\n",
    "        st = obspy.core.read(mseedfile)\n",
    "    else:\n",
    "        st = obspy.core.Stream()\n",
    "        for trace_id in trace_ids:\n",
    "            try:\n",
    "                net, sta, loc, cha = trace_id.split('.')\n",
    "            except:\n",
    "                net, sta, cha = trace_id.split('.')\n",
    "                loc = '*'\n",
    "            try:\n",
    "                st0 = fdsnClient.get_waveforms(net, sta, loc, cha, startt, endt)\n",
    "                print('waveform downloaded for ', trace_id)\n",
    "                if len(st0)==1:\n",
    "                    st.append(st0[0])\n",
    "                else:\n",
    "                    print('More than 1 Trace')\n",
    "                    last_id = ''\n",
    "                    for tr0 in st0:\n",
    "                        if tr0.id != last_id:\n",
    "                            st.append(tr0)\n",
    "                        else:\n",
    "                            st.remove(st[-1])\n",
    "            except:\n",
    "                print('failed to download waveform for ', trace_id)\n",
    "            \n",
    "        # save waveform data\n",
    "        if len(st)>0:\n",
    "            st.write(stationXmlFile.replace('.xml','.mseed'))\n",
    "        \n",
    "    return st, inv\n",
    "\n",
    "def reconstitute_stream(st, inv, fmin=0.0001):\n",
    "    T=1.0/fmin\n",
    "    \n",
    "    # deal with multiple traces with same trace ID, by appending and merging one at a time,\n",
    "    # and removing any time there is a fail.\n",
    "    st2 = obspy.core.Stream()\n",
    "    for tr_original in st:\n",
    "        tr = tr_original.copy()\n",
    "        st2 = st2.append(tr)\n",
    "        try:\n",
    "            st2.merge(method=1, fill_value=0)\n",
    "        except:\n",
    "            st2.remove(tr)\n",
    "            pass\n",
    "        \n",
    "    # reconstitute as many traces as possible, and return them\n",
    "    reconstituted = obspy.core.Stream()\n",
    "    failed_ids = []\n",
    "    for tr_original in st2:\n",
    "        tr = tr_original.copy()\n",
    "        \n",
    "        # remove gappy Trace objects, filled with 0 above (threshold 10%)\n",
    "        n = np.count_nonzero(tr.data==0)\n",
    "        if n/len(tr.data) > 0.1:\n",
    "            st2.remove(tr_original)\n",
    "            continue\n",
    "            \n",
    "        # high pass filter    \n",
    "        tr.detrend('linear')\n",
    "        duration = tr.stats.endtime - tr.stats.starttime\n",
    "        tr.taper(T/duration)\n",
    "        tr.stats['maxamp_raw'] = np.max(np.abs(tr.data))\n",
    "        #tr.filter(\"highpass\", freq=fmin, corners=2)\n",
    "        pre_filt = [fmin, fmin*2, tr.stats.sampling_rate*0.3, tr.stats.sampling_rate*0.4]\n",
    "        \n",
    "        # remove response\n",
    "        try:\n",
    "            if tr.stats.channel[1]=='H':\n",
    "                tr.remove_response(inventory=inv, pre_filt=pre_filt, output='DISP')\n",
    "            else:\n",
    "                tr.remove_response(inventory=inv, pre_filt=pre_filt )\n",
    "            reconstituted.append(tr)\n",
    "            #print(tr.id, ' reconstituted')\n",
    "        except:\n",
    "            #print(tr.id, ' NOT reconstituted')\n",
    "            failed_ids.append(tr.id)\n",
    "            pass\n",
    "        tr.detrend('linear')\n",
    "        tr.stats['maxamp_corrected'] = np.max(np.abs(tr.data))\n",
    "    print('Failed to reconstitute: ', failed_ids)\n",
    "\n",
    "    #reconstituted.plot(equal_scale=True);\n",
    "    \n",
    "    return reconstituted\n",
    "\n",
    "\n",
    "def attach_station_coordinates_from_inventory(inventory, st):\n",
    "    \"\"\" attach_station_coordinates_from_inventory \"\"\"\n",
    "    for tr in st:\n",
    "        for netw in inventory.networks:\n",
    "            for sta in netw.stations:\n",
    "                if tr.stats.station == sta.code and netw.code == tr.stats.network:\n",
    "                    for cha in sta.channels:\n",
    "                        if tr.stats.location == cha.location_code:\n",
    "                            tr.stats.coordinates = obspy.core.util.AttribDict({\n",
    "                                'latitude':cha.latitude,\n",
    "                                'longitude':cha.longitude,\n",
    "                                'elevation':cha.elevation})\n",
    "                            \n",
    "def attach_distance_to_stream(st, olat, olon):\n",
    "    for tr in st:\n",
    "        try:\n",
    "            alat = tr.stats['coordinates']['latitude']\n",
    "            alon = tr.stats['coordinates']['longitude']\n",
    "            distdeg = locations2degrees(olat, olon, alat, alon)\n",
    "            distkm = degrees2kilometers(distdeg)\n",
    "            tr.stats['distance'] =  distkm * 1000\n",
    "        except:\n",
    "            print('cannot compute distance for %s' % tr.id)\n",
    "            \n",
    "def remove_outliers(a, t, f=30, amax=2000, amin=1):\n",
    "    bad_indices = []\n",
    "    \n",
    "    # subset to range amax to amin\n",
    "    for i, v in enumerate(a):\n",
    "        if v > amax:\n",
    "            bad_indices.append(i)\n",
    "        if v < amin:\n",
    "            bad_indices.append(i)            \n",
    "    #print(bad_indices)\n",
    "    if len(bad_indices)>0:\n",
    "        for i in bad_indices:\n",
    "            a[i]=np.NaN \n",
    "            t[i]=np.NaN\n",
    "            \n",
    "    # subset further based on median\n",
    "    m = np.median(a)\n",
    "    bad_indices = []\n",
    "    for i, v in enumerate(a):\n",
    "        if v > m * f:\n",
    "            bad_indices.append(i)\n",
    "        if v * f < m:\n",
    "            bad_indices.append(i)            \n",
    "    #print(bad_indices)\n",
    "    if len(bad_indices)>0:\n",
    "        for i in bad_indices:\n",
    "            a[i]=np.NaN \n",
    "            t[i]=np.NaN\n",
    "    #return a, t\n",
    "    \n",
    "def plot_amplitude_versus_distance(st, units, reftime=None, cmin=300, cmax=420, duration=7200):\n",
    "    r = []\n",
    "    a = []\n",
    "    t = []\n",
    "    for tr in st:\n",
    "        \n",
    "        if reftime:\n",
    "            this_r = tr.stats.distance\n",
    "            Pmax = []\n",
    "            tmax = []\n",
    "            stime = reftime + this_r/cmax\n",
    "            etime = reftime + this_r/cmin + duration\n",
    "            if etime < tr.stats.endtime:\n",
    "                tr0=tr.copy().trim(starttime=stime, endtime=endt)\n",
    "                this_a = np.max(np.abs(tr0.data))\n",
    "                this_t = np.argmax(np.abs(tr0.data))*tr0.stats.delta\n",
    "                Pmax.append(this_a)\n",
    "                tmax.append(this_t)\n",
    "                r.append(this_r/1000)\n",
    "                a.append(this_a)\n",
    "                tr.stats['Pmax']=Pmax\n",
    "                tr.stats['tmax']=tmax\n",
    "                t.append(this_t) \n",
    "                \n",
    "            this_r = circum_earth_m - this_r\n",
    "            stime = reftime + this_r/cmax\n",
    "            etime = reftime + this_r/cmin + duration\n",
    "            if etime < tr.stats.endtime:\n",
    "                tr0=tr.copy().trim(starttime=stime, endtime=endt)\n",
    "                this_a = np.max(np.abs(tr0.data))\n",
    "                this_t = np.argmax(np.abs(tr0.data))*tr0.stats.delta\n",
    "                Pmax.append(this_a)\n",
    "                tmax.append(this_t)\n",
    "                a.append(this_a)\n",
    "                tr.stats['Pmax']=Pmax\n",
    "                tr.stats['tmax']=tmax\n",
    "                t.append(this_t)    \n",
    "                r.append(this_r/1000)\n",
    "        else:\n",
    "            Pmax = np.max(np.abs(tr.data))\n",
    "            tmax = np.argmax(np.abs(tr.data))*tr.stats.delta\n",
    "            a.append(Pmax)\n",
    "            tr.stats['Pmax']=Pmax\n",
    "            tr.stats['tmax']=tmax\n",
    "            t.append(tmax)\n",
    "            r.append(this_r/1000)\n",
    "            \n",
    "    #remove_outliers(a, t) \n",
    "    r2 = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "    r2.extend(r)\n",
    "    PR = 12000\n",
    "    y = PR/np.power(r2,0.5)\n",
    "    \n",
    "    # wavefront circumference does not increase like 1/r as assumed because the earth is curved, not flat.\n",
    "    # so there is a trigonemtric correction to apply. figure this out and use in a better paper, and then\n",
    "    # estimate attenuation from full energy of N-wave. remove this plot for nopw.\n",
    "    y2 = []\n",
    "    r3 = []\n",
    "    radius_earth = circum_earth_m/(2*3.1415)\n",
    "    for this_r in r2: \n",
    "        real_r = radius_earth * np.arcsin(this_r/radius_earth)\n",
    "        print(this_r, real_r)\n",
    "        r3.append(real_r)\n",
    "        y2.append(PR / np.power(real_r, 0.5))\n",
    "    y2 = np.array(y2)\n",
    "    r2 = np.array(r2)\n",
    "    r3 = np.array(r3)\n",
    "    #print(y2)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.loglog(r, a, 'o')\n",
    "    ax.loglog(r2, y, 'r:')\n",
    "    ax.loglog(r2, y2, 'g:')\n",
    "    ax.set_ylim(10,100000)\n",
    "    ax.set_xlim(1,42000)\n",
    "    ax.set_ylabel('Maximum amplitude (%s)' % units)\n",
    "    ax.set_xlabel('Distance (km)')\n",
    "    plt.grid(which='both')\n",
    "    #plt.savefig('reduced_pressure.eps')\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(r2, r3/r2, 'o')\n",
    "    \n",
    "    if False:\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.scatter(t, r)\n",
    "        ax.set_xlabel('Maximum time (s)')\n",
    "        ax.set_ylabel('Distance (km)')\n",
    "        plt.show()    \n",
    "    \n",
    "def plot_reduced_pressure(st, units):\n",
    "    r = []\n",
    "    a = []\n",
    "    for tr in st:\n",
    "        if 'Pmax' in tr.stats:\n",
    "            r.append(tr.stats.distance/1000)\n",
    "            PRmax=tr.stats.Pmax* np.sqrt(tr.stats.distance/1000)\n",
    "            a.append(PRmax)\n",
    "            tr.stats['PRmax']=PRmax\n",
    "    #remove_outliers(a, t, amax=50000, amin=1000)    \n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.scatter(r, a)\n",
    "    ax.set_ylabel('Reduced Pressure (%s)' % units)\n",
    "    ax.set_xlabel('Distance (km)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def yes_or_no(question, default_answer='y', auto=False):\n",
    "    #while \"the answer is invalid\":\n",
    "    if auto==True:\n",
    "        reply = ''\n",
    "    else:\n",
    "        reply = str(input(question+' (y/n): ')).lower().strip()\n",
    "    if len(reply) == 0:\n",
    "        reply = default_answer\n",
    "    if reply[0] == 'y':\n",
    "        return True\n",
    "    if reply[0] == 'n':\n",
    "        return False\n",
    "        \n",
    "def manually_select_good_traces(st2, trim_mins=0, record_section=False, auto=False, wlen=7200, rmax=999999999):\n",
    "    r = get_distance_vector(st2)\n",
    "    st = order_traces_by_distance(st2, r) # sort traces by distance\n",
    "    last_distance = -9999999\n",
    "    last_max_amp = 999999999999\n",
    "    stkeep = obspy.core.Stream()\n",
    "    for tr in st:\n",
    "        startt = tr.stats.starttime + trim_mins * 60\n",
    "        endt = tr.stats.endtime - trim_mins + 60 \n",
    "        if 'arrival' in tr.stats:\n",
    "            print(tr.stats.arrival)\n",
    "            startt = tr.stats.arrival['arrivaltime'] - wlen/10\n",
    "            endt = tr.stats.arrival['arrivaltime'] + wlen + wlen/10\n",
    "        if endt > startt:\n",
    "            tr.trim(starttime=startt, endtime=endt)\n",
    "            tr.plot()\n",
    "            \n",
    "            # only recommend to keep a trace if amplitude less than twice previous\n",
    "            this_max_amp = np.max(np.abs(tr.data))\n",
    "            print('max amp = ', this_max_amp)\n",
    "            this_distance = tr.stats.distance\n",
    "            if this_distance > rmax: # skip if greater than rmax\n",
    "                continue\n",
    "            print('distance = ', this_distance)\n",
    "            recommend = 'n'\n",
    "            if this_max_amp < 2 * last_max_amp:\n",
    "                if record_section: # if record section, only recommend to keep if at least 100 km from previous kept trace\n",
    "                    if this_distance > last_distance + 200000:\n",
    "                        recommend = 'y'\n",
    "                else:\n",
    "                    recommend = 'y'\n",
    "\n",
    "            if yes_or_no('keep this trace? (%s)' % recommend, default_answer=recommend, auto=auto):\n",
    "                stkeep.append(tr.copy())\n",
    "                last_distance = this_distance\n",
    "                last_max_amp = this_max_amp\n",
    "    return stkeep\n",
    "\n",
    "def select_previously_manually_selected_traces(st, good_ids):\n",
    "    stkeep = obspy.core.Stream()\n",
    "    for tr in st:\n",
    "        if tr.id in good_ids:\n",
    "            stkeep.append(tr.copy())\n",
    "    return stkeep\n",
    "\n",
    "def analyze_clientchan(fdsnClient, chanstring, fmin=0.001, network='*', station='*', location='*'):\n",
    "    T = np.round(1/fmin,0)\n",
    "    \n",
    "    this_stream, this_inventory = get_inventory_and_waveforms(fdsnClient, searchRadiusDeg, olat, olon, startt, endt, chanstring, DATA_ROOT, network=network, station=station, location=location, overwrite=False)\n",
    "    attach_station_coordinates_from_inventory(this_inventory, this_stream)\n",
    "    attach_distance_to_stream(this_stream, olat, olon)\n",
    "    \n",
    "    prepend = get_fdsn_identifier(fdsnClient)\n",
    "    this_reconstituted = reconstitute_stream(this_stream, this_inventory, fmin=fmin)\n",
    "    reconfile = os.path.join(DATA_ROOT, '%s%s_reconstituted_%.0f.mseed' % (prepend, chanstring, T))    \n",
    "    #if chanstring[0]!='L':\n",
    "    #    median_downsample_to_1Hz(this_reconstituted)\n",
    "    #    reconfile = os.path.join(DATA_ROOT, '%s%s_reconstituted_%.0f_downsampled.mseed' % (prepend, chanstring, T))\n",
    "    if not os.path.exists(reconfile):\n",
    "        this_reconstituted.write(reconfile)\n",
    "    \n",
    "    good_ids_pickle = os.path.join(DATA_ROOT, '%sgood_%s_ids_within_%.0f_degrees.pkl' % (prepend, chanstring, searchRadiusDeg))\n",
    "    if os.path.exists(good_ids_pickle):\n",
    "        with open(good_ids_pickle, 'rb') as f:\n",
    "            good_ids = pickle.load(f)        \n",
    "        this_good = select_previously_manually_selected_traces(this_reconstituted, good_ids)\n",
    "    else:\n",
    "        this_good = manually_select_good_traces(this_reconstituted)\n",
    "        good_ids = []\n",
    "        for tr in this_good:\n",
    "            good_ids.append(tr.id)\n",
    "        print(good_ids)\n",
    "        print(len(good_ids))\n",
    "        with open(good_ids_pickle, 'wb') as f:\n",
    "            pickle.dump(good_ids, f)    \n",
    "        this_good.write(os.path.join(DATA_ROOT, '%s%s_good.mseed' % (prepend, chanstring)))   \n",
    "    \n",
    "    if chanstring[1]=='D':\n",
    "        units = 'Pa'\n",
    "        plot_amplitude_versus_distance(this_good, units)\n",
    "        plot_reduced_pressure(this_good, units)\n",
    "    #elif chanstring[1]=='H':\n",
    "    #    units = 'm/s'\n",
    "    #    plot_amplitude_versus_distance(this_good, units)       \n",
    "    \n",
    "    good_inv = subset_inv(this_inventory, this_stream, this_good)\n",
    "    plot_inv(good_inv)\n",
    "    \n",
    "    return this_good, good_inv, this_stream, this_inventory\n",
    "\n",
    "def subset_inv(inv, st, st_subset):\n",
    "    # subset an inventory based on a stream object which is a subset of another\n",
    "    try:\n",
    "        inv_new = inv.copy() # got an error here once that Inventory has no copy(), but it does\n",
    "        for tr in st:\n",
    "            if len(st_subset.select(id=tr.id))==0:\n",
    "                inv_new = inv_new.remove(network=tr.stats.network, station=tr.stats.station, location=tr.stats.location, channel=tr.stats.channel)\n",
    "        return inv_new\n",
    "    except:\n",
    "        print('Failed to subset inventory. Returning unchanged')\n",
    "        return inv\n",
    "\n",
    "def plot_inv(inv):\n",
    "    inv.plot(water_fill_color=[0.0, 0.5, 0.8], continent_fill_color=[0.1, 0.6, 0.1], size=30);\n",
    "    \n",
    "def medfilt(x, k):\n",
    "    \"\"\"Apply a length-k median filter to a 1D array x.\n",
    "    Boundaries are extended by repeating endpoints.\n",
    "    \"\"\"\n",
    "    assert k % 2 == 1, \"Median filter length must be odd.\"\n",
    "    assert x.ndim == 1, \"Input must be one-dimensional.\"\n",
    "    k2 = (k - 1) // 2\n",
    "    y = np.zeros ((len (x), k), dtype=x.dtype)\n",
    "    y[:,k2] = x\n",
    "    for i in range (k2):\n",
    "        j = k2 - i\n",
    "        y[j:,i] = x[:-j]\n",
    "        y[:j,i] = x[0]\n",
    "        y[:-j,-(i+1)] = x[j:]\n",
    "        y[-j:,-(i+1)] = x[-1]\n",
    "    return np.median(y, axis=1)\n",
    "\n",
    "\n",
    "def median_downsample_to_1Hz(st, winlec_sec=1.0):\n",
    "    for tr in st:\n",
    "        y = medfilt(tr.data, np.round(winlen_secs / tr.stats.delta,0) )\n",
    "        fs = np.round(tr.stats.sampling_rate,0)\n",
    "        if fs>=2.0:\n",
    "            fs_new = tr.stats.sampling_rate/fs\n",
    "            tr.data = y[0::fs]\n",
    "            tr.stats.sampling_rate=fs_new\n",
    "\n",
    "            \n",
    "def plots(this_good, inv, olat, olon, otime, startt=0, endt=0, minf=0, maxf=0, auto=False, cmin=300, cmax=420):  \n",
    "\n",
    "    st = this_good.copy()\n",
    "    if endt>startt:\n",
    "        st.trim(starttime=startt, endtime=endt)\n",
    "    if minf>0:\n",
    "        st.filter('highpass', freq=minf, corners=2 )\n",
    "    if maxf>0:\n",
    "        st.filter('lowpass', freq=maxf, corners=2 )\n",
    "    plot_amplitude_versus_distance(st, 'Pa', reftime=otime, cmin=300, cmax=420)\n",
    "    plot_reduced_pressure(st, 'Pa')   \n",
    "    plot_inv(inv)\n",
    "\n",
    "    ntraces = len(st)\n",
    "    nsamples = len(st[0].data)    \n",
    "    if nsamples * ntraces > 3600 * 30 * 50: # no more than 1 sample per second for 30 hours for 50 traces\n",
    "        st.decimate(8)\n",
    "    print('Select good traces for record section')\n",
    "    st2 = manually_select_good_traces(st, record_section=True, auto=auto)    \n",
    "    st2.plot(type='section', scale=10, norm_method='stream', orientation='horizontal', dist_degree=True, ev_coord=[olat,olon]) #, reftime=otime)\n",
    "\n",
    "def get_distance_vector(st):\n",
    "    r = []\n",
    "    for tr in st:\n",
    "        r.append(tr.stats.distance)\n",
    "    return r\n",
    "        \n",
    "    \n",
    "def order_traces_by_distance(st, r): \n",
    "    st2 = obspy.core.Stream()\n",
    "    indices = np.argsort(r)\n",
    "    #print(indices)\n",
    "    for i in indices:\n",
    "        tr = st[i].copy()\n",
    "        st2.append(tr)\n",
    "        #print(tr)\n",
    "    return st2\n",
    "\n",
    "def pick_pressure_onset(st, otime, cmin, cmax):\n",
    "    print('Pick onset times with left mouse button. Middle button to skip trace.')\n",
    "    for tr in st:\n",
    "        mintime = otime + tr.stats.distance/cmax\n",
    "        maxtime = otime + tr.stats.distance/cmin\n",
    "        winsecs = maxtime - mintime\n",
    "        \n",
    "        good_trace = False\n",
    "        \n",
    "        while winsecs > 180:\n",
    "            tr2 = tr.copy().trim(starttime=mintime, endtime=maxtime)\n",
    "            t = np.arange(0,tr2.stats.delta*len(tr2.data),tr2.stats.delta)\n",
    "            plt.plot(t, tr2.data)\n",
    "            plt.title(tr.id)\n",
    "            plt.show()\n",
    "            pos = plt.ginput(1, timeout=12.0, show_clicks=True )\n",
    "            plt.close()\n",
    "            if len(pos)>0:\n",
    "                if len(pos[0])>0:\n",
    "                    good_trace = True\n",
    "                    x = pos[0][0]\n",
    "                    atime = tr2.stats.starttime + x\n",
    "                    print(atime)\n",
    "                    winsecs = winsecs / 5\n",
    "                    mintime = atime - winsecs/2\n",
    "                    maxtime = atime + winsecs/2 \n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        if good_trace:\n",
    "            traveltime = atime - otime\n",
    "            tr.stats['arrival'] = obspy.core.util.AttribDict({\n",
    "                                'arrivaltime':atime,\n",
    "                                'c':tr.stats.distance/traveltime,\n",
    "                                'traveltime':traveltime})\n",
    "            print(tr.stats.arrival)\n",
    "        \n",
    "\n",
    "def regress_arrival_times(st, reftime, outfile=None):\n",
    "    fh = plt.figure(figsize=(16,16))\n",
    "    ah = fh.add_subplot(1,1,1)\n",
    "    atimes=[]\n",
    "    r=[]\n",
    "    for i, tr in enumerate(st):   \n",
    "        if 'arrival' in tr.stats:\n",
    "            r.append(tr.stats.distance) \n",
    "            atimes.append(tr.stats.arrival.arrivaltime - reftime)  \n",
    "    atimes = np.array(atimes)\n",
    "    r = np.array(r)\n",
    "    #m, c = np.polyfit(atimes, r, deg=1)\n",
    "    wavespeed, d_intercept, r_value, p_value, std_err = linregress(atimes, r)\n",
    "    ah.plot(atimes, r, 'bx') # data\n",
    "    t_intercept = -d_intercept/wavespeed\n",
    "    t = np.arange(min([t_intercept,0.0]), np.max(atimes), np.max(atimes)/1000) # 1000 steps\n",
    "    d = wavespeed * t + d_intercept\n",
    "    ah.plot(t, d) # line\n",
    "    new_otime = reftime + t_intercept\n",
    "    #print(wavespeed, d_intercept, t_intercept, r_value, p_value, std_err)\n",
    "    print('infrasonic wave speed = %.1f m/s, origin time = %s' % (wavespeed, new_otime.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    ah.set_ylabel('Distance (m)')\n",
    "    ah.set_xlabel('Time (seconds) after %s' % reftime.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    #ah.set_ylim(-1e5, 1e5)\n",
    "    #ah.set_xlim(-1e3, 3e1)\n",
    "    ah.grid()\n",
    "    speed_to_nearest_station = st[0].stats.distance / (st[0].stats.arrival.arrivaltime - new_otime)\n",
    "    print('Average speed to station %s at %.1f km is %.1f m/s' % (st[0].stats.station, st[0].stats.distance/1000, speed_to_nearest_station ))\n",
    "    print('To fit earthquake time, speed is %.1f m/s' % (st[0].stats.distance / (st[0].stats.arrival.arrivaltime - reftime)))\n",
    "\n",
    "    if outfile:\n",
    "        fh.savefig(outfile)\n",
    "    return wavespeed, new_otime, t, d\n",
    "\n",
    "def plot_record_section(st2, reftime, outfile=None, starttime=0, endtime=0, \\\n",
    "                        km_min=0, km_max=40075.0/2, slopes = [], \\\n",
    "                        scale_factor=1.0, plot_arrivals=False, \\\n",
    "                        figsize=(16,16), min_spacing_km=0, reduced_speed=None, normalize=False ):\n",
    "    r = np.array(get_distance_vector(st2))\n",
    "    st = order_traces_by_distance(st2, r)\n",
    "\n",
    "\n",
    "        \n",
    "    if reduced_speed:\n",
    "        for tr in st: # need to remove travel time from traces by altering starttime\n",
    "            time_change = tr.stats.distance/reduced_speed\n",
    "            tr.stats.starttime = tr.stats.starttime - time_change\n",
    "            \n",
    "        \n",
    "    if endtime>starttime:\n",
    "        print('Trimming')\n",
    "        st.trim(starttime=starttime, endtime=endtime) \n",
    "        \n",
    "    if normalize:\n",
    "        st.normalize(global_max=False)\n",
    "    \n",
    "    rmax = np.max(r)\n",
    "    l = len(st)\n",
    "    max_trace_height = scale_factor/l *(km_max-km_min)\n",
    "    #st.normalize(global_max=True) \n",
    "    km_per_Pa = 1.0\n",
    "    last_r = -9999999\n",
    "    last_asecs = -99999999\n",
    "    if min_spacing_km == 0:\n",
    "        min_spacing_km = 111.0  * km_max/20037.5\n",
    "    max_pascals = 1500\n",
    "    \n",
    "    \n",
    "    fh = plt.figure(figsize=figsize)\n",
    "    ah = fh.add_subplot(1,1,1)\n",
    "    for i, tr in enumerate(st):\n",
    "\n",
    "        tr.detrend('linear')\n",
    "        if np.max(np.abs(tr.data))>max_pascals:\n",
    "            continue\n",
    "        \n",
    "        # distance to station and offset in km\n",
    "        this_r = tr.stats.distance\n",
    "        offset_km = this_r/1000\n",
    " \n",
    "        # plot arrival time\n",
    "        if 'arrival' in tr.stats:\n",
    "            asecs = tr.stats.arrival.arrivaltime - reftime\n",
    "            #if asecs < last_asecs:\n",
    "            #    continue\n",
    "            if plot_arrivals:\n",
    "                ahours = asecs/3600\n",
    "                ah.plot(ahours, offset_km, 'b.', zorder=len(st)*2+11-i)        \n",
    "            last_asecs = asecs\n",
    "        \n",
    "        # time\n",
    "        t0 = tr.stats.starttime - reftime\n",
    "        t = t0 + np.arange(0, tr.stats.delta*len(tr.data), tr.stats.delta)     \n",
    "        h = t/3600.0\n",
    "        max_h = np.max(h) \n",
    "        \n",
    "        # color\n",
    "        diff_r = this_r - last_r\n",
    "        brightness = 0\n",
    "        if diff_r < min_spacing_km*1000:\n",
    "            if diff_r < min_spacing_km/2 * 1000:\n",
    "                continue\n",
    "            brightness = 1.0 - (diff_r/1000)/min_spacing_km\n",
    "            last_r = this_r\n",
    "        else:\n",
    "            last_r = this_r\n",
    "        col = [brightness, brightness, brightness]\n",
    "            \n",
    "        # plot\n",
    "        ah.plot(h, offset_km+(tr.data * km_per_Pa * scale_factor), \\\n",
    "                color=col, linewidth=0.5, zorder=(len(st)*2+10-i)*(1.0-brightness) )\n",
    "\n",
    "        \n",
    "    if len(slopes)>0:\n",
    "        print(slopes)\n",
    "        for slope in slopes:\n",
    "            print(slope)\n",
    "            slope_speed = slope[0]\n",
    "            slope_origintime = slope[1]\n",
    "            if len(slope)==2:\n",
    "                slope.append('r-')\n",
    "            t_prime = np.array([km_min*1000/slope_speed, km_max*1000/slope_speed]) \n",
    "            d_prime = np.array([km_min, km_max])\n",
    "            t_prime = d_prime*1000/slope_speed + (slope_origintime - st[0].stats.starttime)\n",
    "            h_prime = t_prime/3600\n",
    "            ah.plot(h_prime, d_prime, slope[2], zorder=900 )\n",
    "\n",
    "        \n",
    "    ah.set_yticks(np.arange(km_min, km_max, 1000.0))\n",
    "    numhours = h[-1]-h[0]\n",
    "    if numhours>20:\n",
    "        stephours = np.round(numhours/20,0)\n",
    "    else:\n",
    "        stephours = np.round(numhours/20,1)\n",
    "    #ah.set_xticks(np.arange(t[0], t[-1], 1.0))\n",
    "    ah.set_xticks(np.arange(h[0], h[-1], stephours))\n",
    "    ah.set_xlim(h[0],h[-1])\n",
    "    ah.set_ylabel('Distance (km)')\n",
    "    ah.set_xlabel('Time (hours) after %s' % reftime.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    #ah.xaxis.set_major_formatter(plt.FuncFormatter('{:.0f}'.format))\n",
    "    ah.yaxis.set_major_formatter(plt.FuncFormatter('{:.0f}'.format))\n",
    "    #ah.autoscale(enable=True, tight=True)\n",
    "    #ah.set_ylim(0, circum_earth_km/2)\n",
    "    ah.set_ylim(km_min, km_max)\n",
    "    ah.grid(axis='x', color = 'green', linestyle = ':', linewidth = 0.5)\n",
    "    \n",
    "    two_axes = True\n",
    "    if two_axes:\n",
    "        ah2 = ah.twinx()\n",
    "        #y2 = [km_min/m_per_deg, rmax/m_per_deg]\n",
    "        y2 = [1000*km_min/m_per_deg, 1000*km_max/m_per_deg]\n",
    "        ah2.plot([0, 0],y2,'k-')\n",
    "        ylim_km = ah.get_ylim()\n",
    "        #ah2.set_ylim(ylim_km[0]*1000/m_per_deg, ylim_km[1]*1000/m_per_deg)\n",
    "        ah2.set_ylabel('Distance (degrees)')\n",
    "        #ah2.set_ylim(0, 180)\n",
    "        ah2.set_ylim(1000*km_min/m_per_deg, 1000*km_max/m_per_deg)\n",
    "\n",
    "    if outfile:\n",
    "        fh.savefig(outfile)\n",
    "\n",
    "def plot_combined_versus_distance(st_list, inv_list, units, corrected=False):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax = fig.add_subplot(1,1,1)   \n",
    "    cols = ['r','g','b']\n",
    "    labels = ['IRIS LDF', 'IRIS LDO', 'RBOOM']\n",
    "    for i, st_original in enumerate(st_list):\n",
    "        st = st_original.copy()\n",
    "        inv = inv_list[i]\n",
    "        attach_station_coordinates_from_inventory(inv, st)\n",
    "        attach_distance_to_stream(st, olat, olon)\n",
    "        st.trim(starttime=startt+1*60, endtime=startt+18*3600) # just examine first pulse\n",
    "        r = []\n",
    "        a = []\n",
    "        for tr in st:\n",
    "            r.append(tr.stats.distance_in_km)\n",
    "            #a.append(tr.stats.maxamp_corrected)\n",
    "            if corrected:\n",
    "                a.append(np.max(np.abs(tr.data))* np.sqrt(tr.stats.distance_in_km))\n",
    "            else:\n",
    "                a.append(np.max(np.abs(tr.data)))\n",
    "        remove_outliers(a, f=100)     \n",
    "        ax.scatter(r, a, c=cols[i], label=labels[i])\n",
    "    if corrected:\n",
    "        ax.set_ylabel('Reduced Pressure (%s)' % units)\n",
    "    else:\n",
    "        ax.set_ylabel('Maximum amplitude (%s)' % units)\n",
    "    ax.set_xlabel('Distance (km)')\n",
    "    ax.legend()\n",
    "    plt.show()       \n",
    "    \n",
    "    \n",
    "def remove_duplicates(st):\n",
    "    st2 = obspy.core.Stream()\n",
    "    for tr_original in st:\n",
    "        tr = tr_original.copy()\n",
    "        st2.append(tr)\n",
    "        try:\n",
    "            st2.merge(method=1, fill_value=0)\n",
    "        except:\n",
    "            st2.remove(tr)\n",
    "    return st2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = os.path.join(os.getenv('HOME'), 'DATA', 'Tonga_eruption_analysis')\n",
    "if not os.path.isdir(DATA_ROOT):\n",
    "    os.makedirs(DATA_ROOT)\n",
    "searchRadiusDeg = 180\n",
    "fmin = 0.0001\n",
    "T = 1.0/fmin\n",
    "circum_earth_km = 40075\n",
    "circum_earth_m = circum_earth_km*1000\n",
    "m_per_deg = circum_earth_m/360.0\n",
    "\n",
    "# location of Hunga-Tonga Hunga-Ha'apai\n",
    "olat = -(20 + 34/60 + 12 /3600) \n",
    "olon = -(175 + 22/60 + 48/3600)\n",
    "otime = obspy.core.UTCDateTime('2022-01-15T04:14:45.000000Z') # main eruption time - on day 2\n",
    "\n",
    "startt =  obspy.core.UTCDateTime('2022-01-13T00:00:00.000000Z') - T*2\n",
    "endt = obspy.core.UTCDateTime('2022-01-20T00:00:00.000000Z') + T*2 # get 34 hours of data, since this is approximate time for sound waves to circle the earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run for barometers outside (LDO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pklfile = os.path.join(DATA_ROOT, 'st_ldo_downsample_pick.pkl')\n",
    "if os.path.isfile(pklfile): # read data from pickle file and leap to 3.1.3\n",
    "    with open(pklfile, 'rb') as f:\n",
    "        st_ldo_downsample_pick = pickle.load(f)\n",
    "else:\n",
    "    fdsnURL = \"http://service.iris.edu\"\n",
    "    chanstring = 'LDO'\n",
    "    st_ldo, inv_ldo, raw_st_ldo, raw_inv_ldo = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do:\n",
    "- compute moveout speed of N wave peak times\n",
    "- correct for actual circumference of wavefronts on a spherical earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pick N-wave onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_1(st, otime=otime, cmin=300, cmax=430, decimation_factor=10):\n",
    "    st_downsample = st.copy()\n",
    "    st_downsample.decimate(decimation_factor)\n",
    "    r = get_distance_vector(st_downsample)\n",
    "    print(r)\n",
    "    st_downsample_pick = order_traces_by_distance(st_downsample, r) \n",
    "    st_downsample_pick = manually_select_good_traces(st_downsample_pick, trim_mins=0, record_section=False, auto=False, wlen=7200)\n",
    "    #pick_pressure_onset(st_downsample_pick, otime, cmin, cmax)\n",
    "    return st_downsample_pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Raw traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_ldo_raw_downsample_pick = process_1(st_ldo_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Reconstituted \"good\" traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_ldo_downsample_pick = process_1(st_ldo)\n",
    "\n",
    "new_otime = obspy.UTCDateTime(2022,1,15,4,7,18)\n",
    "\n",
    "for tr in st_ldo_downsample_pick:\n",
    "    if tr.stats.network == 'PB':\n",
    "        st_ldo_downsample_pick.remove(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_amplitude_versus_distance(st_ldo_downsample_pick, 'Pa', reftime=new_otime, \\\n",
    "                               cmin=300, cmax=420, duration=7200)\n",
    "#plot_reduced_pressure(st, 'Pa')   \n",
    "#plot_inv(inv)\n",
    "#plots(st_ldo_downsample_pick, inv_ldo, olat, olon, otime, cmin=300, cmax=420)\n",
    "print(len(st_ldo_downsample_pick))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Make record section of the N wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal_duration = 3600.0 * 3.0\n",
    "#wavespeed, new_otime, t, d = regress_arrival_times(st2, otime, outfile='Nwave_arrivalfit.eps')\n",
    "wavespeed = 312.7\n",
    "new_otime = obspy.UTCDateTime(2022,1,15,4,7,18)\n",
    "etime = new_otime + (circum_earth_m/2)/wavespeed + signal_duration\n",
    "#plot_record_section(st_ldo_downsample_pick, new_otime, starttime=new_otime, endtime=etime, \\\n",
    "#                    outfile='Nwave_recordsection.eps', slope_speed=wavespeed, figsize=(8,16), scale_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_record_section(st_ldo_downsample_pick, new_otime, starttime=new_otime, endtime=etime, \\\n",
    "#                    outfile='Nwave_recordsection2.eps', slope_speed=wavespeed, figsize=(6,12), scale_factor=3)\n",
    "reftime = obspy.UTCDateTime(2022,1,15,3,0,0)\n",
    "stime = reftime\n",
    "etime = obspy.UTCDateTime(2022,1,16,16,0,0)\n",
    "celerity = 315.0\n",
    "wraptime = circum_earth_m/celerity\n",
    "plot_record_section(st_ldo_downsample_pick, reftime, starttime=stime, endtime=etime, \\\n",
    "                    outfile='Nwave_recordsection5.eps', slopes=[[celerity, otime], [-celerity, otime+wraptime]], figsize=(6,12), scale_factor=3, min_spacing_km=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = obspy.UTCDateTime(2022,1,15,4,0,0)\n",
    "etime = obspy.UTCDateTime(2022,1,15,6,0,0)\n",
    "reftime = stime\n",
    "plot_record_section(st_ldo_downsample_pick, reftime, starttime=stime, endtime=etime, \\\n",
    "    outfile='Nwave_recordsection3.eps', figsize=(12,12), scale_factor=1000, normalize=True, reduced_speed=315, min_spacing_km=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 make record section of multiple passes of N wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "etime2 = obspy.UTCDateTime(2022,1,20,0,0,0)\n",
    "st5 = st_ldo_downsample_pick.copy().filter('bandpass', freqmin=0.01, freqmax=0.1, corners=2)\n",
    "plot_record_section(st5, new_otime, starttime=new_otime, endtime=etime2, \\\n",
    "    outfile='Nwave_recordsection4.eps', figsize=(16,16), scale_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stime2 = obspy.UTCDateTime(2022,1,15,0,0,0)\n",
    "etime2 = obspy.UTCDateTime(2022,1,20,0,0,0)\n",
    "st_ldo_lowpass = st_ldo_downsample_pick.copy().filter('bandpass', freqmin=0.0002, freqmax=0.01, corners=6)\n",
    "wavespeed=310.0\n",
    "wraptime = circum_earth_m/wavespeed \n",
    "plot_record_section(st_ldo_lowpass, stime2, starttime=stime2, endtime=etime2, \\\n",
    "    outfile='Nwave_recordsection_long_master.eps', \\\n",
    "                    slopes=[[wavespeed, new_otime],\\\n",
    "                            [-wavespeed, new_otime+wraptime], \\\n",
    "                            [wavespeed, new_otime+wraptime], \\\n",
    "                            [-wavespeed, new_otime+wraptime*2], \\\n",
    "                            [wavespeed, new_otime+wraptime*2], \\\n",
    "                            [-wavespeed, new_otime+wraptime*3], \\\n",
    "                            [wavespeed, new_otime+wraptime*3], \\\n",
    "                           ], \\\n",
    "                    figsize=(12,12), scale_factor=10, min_spacing_km = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Save reconstituted, downsampled, picked barometric data to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklfile = os.path.join(DATA_ROOT, 'st_ldo_downsample_pick.pkl')\n",
    "with open(pklfile, 'wb') as f:\n",
    "    pickle.dump(st_ldo_downsample_pick, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Explore the near stations only to improve origin time estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Read raw barometric data and order traces by distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklfile = os.path.join(DATA_ROOT, 'st_ldo_raw.pkl')\n",
    "if os.path.isfile(pklfile):\n",
    "    with open(pklfile, 'rb') as f:\n",
    "        st_ldo_raw_sorted = pickle.load(f)\n",
    "else:\n",
    "    #st_ldo_raw = obspy.core.read(os.path.join(DATA_ROOT, 'iris_LDO_within_180_degrees.mseed'))\n",
    "    #inv_ldo_raw = obspy.read_inventory(os.path.join(DATA_ROOT, 'iris_LDO_within_180_degrees.xml'))\n",
    "    #attach_station_coordinates_from_inventory(inv_ldo_raw, st_ldo_raw)\n",
    "    #attach_distance_to_stream(st_ldo_raw, olat, olon)\n",
    "    #r = get_distance_vector(st_ldo_raw)\n",
    "    #st_ldo_raw_sorted = order_traces_by_distance(st_ldo_raw, r) \n",
    "\n",
    "    with open(pklfile, 'wb') as f:\n",
    "        pickle.dump(st_ldo_raw_sorted, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = get_distance_vector(st_ldo_raw_sorted)\n",
    "st_sorted = order_traces_by_distance(st_ldo_raw_sorted, r) \n",
    "st2 = remove_duplicates(stkeep_sorted)\n",
    "st2.detrend('linear')\n",
    "st3 = st2.copy().trim(starttime=obspy.UTCDateTime(2022,1,15,3,0,0), endtime=obspy.UTCDateTime(2022,1,15,7,0,0))\n",
    "#stkeep = manually_select_good_traces(st, trim_mins=0, record_section=False, auto=False, wlen=7200, rmax=3200000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#stkeep2.plot(equal_scale=False)\n",
    "stime = obspy.UTCDateTime(2022,1,15,4,0,0)\n",
    "stkeep2.normalize()\n",
    "plot_record_section(stkeep2, stime, \\\n",
    "    outfile='Nwave_raw_close.eps', figsize=(16,16), scale_factor=500, km_max=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stkeep3 = stkeep2.copy().filter('highpass', freq=0.01, corners=2)\n",
    "\n",
    "plot_record_section(stkeep3, stime, \\\n",
    "    outfile='Nwave_raw_close.eps', figsize=(16,16), scale_factor=500, km_max=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "pick_pressure_onset(stkeep3, new_otime, 250, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_arrival_times(stkeep3, new_otime, outfile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_record_section(stkeep3, stime, \\\n",
    "    outfile='Nwave_raw_close.eps', figsize=(16,16), scale_factor=500, km_max=3500, slopes=[[295.7, obspy.UTCDateTime(2022,1,15,4,1,28)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stkeep2[1].plot(type='dayplot');\n",
    "tr = st_ldo_raw_sorted[0].copy()\n",
    "tr.trim(starttime=stime+1800, endtime=stime+7200)\n",
    "tr.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "757000/(42*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miscellaneous stuff\n",
    "\n",
    "plots(st, inv_ldo, olat, olon, otime, minf=0, auto=True)\n",
    "\n",
    "r = get_distance_vector(st_ldo)\n",
    "st = order_traces_by_distance(st_ldo, r) \n",
    "# sort traces by distance\n",
    "for tr in st:\n",
    "    print(tr.id, tr.stats.distance)\n",
    "\n",
    "plots(st, inv_ldo, olat, olon, otime, startt=otime-200000, endt=otime, auto=True, minf=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run for seismic channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklfile = os.path.join(DATA_ROOT, 'st_lhz_downsample_pick.pkl')\n",
    "if os.path.isfile(pklfile):\n",
    "    with open(pklfile, 'rb') as f:\n",
    "        st_lhz_downsample_pick = pickle.load(f) \n",
    "    \n",
    "else:\n",
    "\n",
    "    fdsnURL = \"http://service.iris.edu\"\n",
    "    chanstring = 'LHZ'\n",
    "    st_lhz, inv_lhz, st_lhz_raw, inv_lhz_raw = analyze_clientchan(fdsnURL, chanstring, fmin=0.005, network='IU')\n",
    "\n",
    "    st_lhz_downsample_pick = process_1(st_lhz)\n",
    "    \n",
    "    with open(pklfile, 'wb') as f:\n",
    "        pickle.dump(st_lhz_downsample_pick, f)     \n",
    "\n",
    "st_f = st_lhz_downsample_pick.copy().filter('bandpass', freqmin=0.001, freqmax=0.01, corners=2)\n",
    "signal_duration = 3600.0 * 3.0\n",
    "wavespeed = 312.7\n",
    "new_otime = obspy.UTCDateTime(2022,1,15,4,7,18)\n",
    "etime = new_otime + (circum_earth_m/2)/wavespeed + signal_duration\n",
    "plot_record_section(st_f, new_otime, starttime=new_otime, endtime=etime, \\\n",
    "    outfile='seismicwave_recordsection.eps', figsize=(8,16), scale_factor=2e8, slope_speed=wavespeed)\n",
    "\n",
    "etime = new_otime + 3 * 3600\n",
    "plot_record_section(st_lhz_downsample_pick, new_otime, starttime=new_otime, endtime=etime, \\\n",
    "    outfile='seismicwave_recordsection_short.eps', figsize=(8,16), scale_factor=1e8)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = obspy.UTCDateTime(2022,1,15,0,0,0)\n",
    "etime = obspy.UTCDateTime(2022,1,17,0,0,0)\n",
    "st_f2 = st_lhz_downsample_pick.copy().filter('bandpass', freqmin=0.005, freqmax=0.02, corners=2)\n",
    "plot_record_section(st_f2, stime, starttime=stime, endtime=etime, \\\n",
    "    outfile='seismicwave_recordsection.eps', figsize=(6,12), scale_factor=6e8, min_spacing_km = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_lhz_raw = obspy.core.read(os.path.join(DATA_ROOT, 'iris_LHZ_within_180_degrees.mseed'))\n",
    "inv_lhz_raw = obspy.read_inventory(os.path.join(DATA_ROOT, 'iris_LHZ_within_180_degrees.xml'))\n",
    "attach_station_coordinates_from_inventory(inv_lhz_raw, st_lhz_raw)\n",
    "attach_distance_to_stream(st_lhz_raw, olat, olon)\n",
    "reftime = obspy.UTCDateTime(2022,1,15,4,0,0)\n",
    "stime = reftime\n",
    "etime = obspy.UTCDateTime(2022,1,15,6,0,0)\n",
    "celerity = 300.0\n",
    "wraptime = circum_earth_m/celerity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = st_lhz_raw.copy()\n",
    "st.filter('bandpass', freqmin=0.005, freqmax=0.02)\n",
    "st.trim(starttime=stime-3600,endtime=etime+3600)\n",
    "st.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_f3=st_f2.copy().normalize()\n",
    "plot_record_section(st_f3, reftime, starttime=stime, endtime=etime, \\\n",
    "    outfile='seismicwave_recordsection5.eps', slopes=[[celerity, otime], \\\n",
    "    [-celerity, otime+wraptime], [4000, otime]], figsize=(6,12), scale_factor=3000, min_spacing_km=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_f2 = st_lhz_downsample_pick.copy().filter('bandpass', freqmin=0.001, freqmax=0.02, corners=2)\n",
    "st_f3 = st_f2.copy().trim(starttime=stime-3600, endtime=etime+3600)\n",
    "st_f4 = st_f3.copy().normalize(global_max=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reftime = obspy.UTCDateTime(2022,1,15,3,0,0)\n",
    "stime = reftime\n",
    "etime = obspy.UTCDateTime(2022,1,16,16,0,0)\n",
    "celerity = 300.0\n",
    "wraptime = circum_earth_m/celerity\n",
    "plot_record_section(st_f4, reftime, starttime=stime, endtime=etime, \\\n",
    "    outfile='seismicwave_recordsection_1pass_master.eps', slopes=[[3600, otime, 'b-'],[315.0, otime, 'r-'], [celerity, otime, 'g-'], [-celerity, otime+wraptime, 'g-']], figsize=(6,12), scale_factor=1000, min_spacing_km=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_distance_vector(st_lhz)\n",
    "st_lhz_sorted = order_traces_by_distance(st_lhz, r) \n",
    "plots(st_lhz_sorted, inv_ldo, olat, olon, otime, startt=otime, endt=otime+12*3600, auto=True, minf=0.001, maxf=0.1)\n",
    "\n",
    "r = get_distance_vector(st_ldo)\n",
    "st_ldo_sorted = order_traces_by_distance(st_ldo, r) \n",
    "plots(st_ldo_sorted, inv_ldo, olat, olon, otime, startt=otime, endt=otime+12*3600, auto=True, minf=0.001, maxf=0.1)\n",
    "\n",
    "r = get_distance_vector(st_ldo)\n",
    "st_ldo_sorted = order_traces_by_distance(st_ldo, r) \n",
    "plots(st_ldo_sorted, inv_ldo, olat, olon, otime, startt=otime, endt=st_ldo[0].stats.endtime, auto=True, minf=0.00015, maxf=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run for infrasound channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdsnURL = \"http://service.iris.edu\"\n",
    "chanstring = 'LDF'\n",
    "st_ldf, inv_ldf, raw_st_ldf, raw_inv_ldf  = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)\n",
    "plots(st_ldf, otime, otime+17*3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run for Raspberry Booms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdsnURL = \"http://fdsnws.raspberryshakedata.com\"\n",
    "chanstring = 'HDF'\n",
    "st_boom, inv_boom, raw_st_boom, raw_inv_boom  = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Combine results in single graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_list = [st_ldf, st_ldo, st_boom]\n",
    "inv_list = [inv_ldf, inv_ldo, inv_boom]\n",
    "units = 'Pa'\n",
    "plot_combined_versus_distance(st_list, inv_list, units, corrected=False)\n",
    "plot_combined_versus_distance(st_list, inv_list, units, corrected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in st_list:\n",
    "    print(len(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- downsample H?? and B?? channels to 1 sample per second\n",
    "- apply data quality metrics to remove bad channels\n",
    "- extra steps to remove spikes?\n",
    "- detect events?\n",
    "- examine as a function of low-cut frequency\n",
    "- make maps with pygmt, e.g. with radius contours, or amplitude contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin=1/10000\n",
    "\n",
    "fdsnURL = \"http://service.iris.edu\"\n",
    "chanstring = 'LDO'\n",
    "st_ldo2, inv_ldo2 = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)\n",
    "\n",
    "fdsnURL = \"http://service.iris.edu\"\n",
    "chanstring = 'LDF'\n",
    "st_ldf2, inv_ldf2 = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)\n",
    "\n",
    "fdsnURL = \"http://fdsnws.raspberryshakedata.com\"\n",
    "chanstring = 'HDF'\n",
    "st_boom2, inv_boom2 = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_list = [st_ldf2, st_ldo2]\n",
    "inv_list = [inv_ldf2, inv_ldo2]\n",
    "units = 'Pa'\n",
    "plot_combined_versus_distance(st_list, inv_list, units, corrected=False)\n",
    "plot_combined_versus_distance(st_list, inv_list, units, corrected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot traces by distance - record section?\n",
    "st = obspy.core.Stream()\n",
    "for tr in st_ldo2:\n",
    "    tr.stats['distance']=tr.stats.distance_in_km*1000.0\n",
    "    tr.data=tr.data*10\n",
    "    st.append(tr)\n",
    "for tr in st_ldf2:\n",
    "    tr.stats['distance']=tr.stats.distance_in_km*1000.0\n",
    "    tr.data=tr.data*10\n",
    "    st.append(tr)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionpng = os.path.join(DATA_ROOT,'section.png')\n",
    "st.plot(type='section',title='',dpi=75,scale=15.0,reftime=otime,norm_method='stream',fillcolors=['r','b'],outfile=sectionpng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(st_ldo2),len(st_ldf2),len(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Investigate filter bandwidth needed to see signal fully at MSVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = obspy.core.read(os.path.join(DATA_ROOT, 'iris_LDO_within_180_degrees.mseed'))\n",
    "#st.select(station='MSVF').plot()\n",
    "inv = obspy.read_inventory(os.path.join(DATA_ROOT, 'iris_LDO_within_180_degrees.xml'))\n",
    "msvf = st.select(station='MSVF')\n",
    "msvf2=msvf.copy()\n",
    "msvf2.remove_response(inventory=inv)\n",
    "msvf2.plot()\n",
    "tr = msvf2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.power(1.2,np.arange(-55,-1))\n",
    "f = f[f<0.5]\n",
    "plt.figure()\n",
    "print(f)\n",
    "for ncorners in range(6):\n",
    "    a = []\n",
    "    for fmin in f:\n",
    "        tr2 = tr.copy()\n",
    "        if fmin>0.0:\n",
    "            #print(fmin)\n",
    "            tr2.filter('highpass',freq=fmin,corners=ncorners+1)\n",
    "        a.append(np.max(np.abs(tr2.data)))\n",
    "    labstr = \"%d corners\" % (ncorners+1)\n",
    "    plt.semilogx(f,a,label=labstr)\n",
    "plt.ylabel('Pa')\n",
    "plt.xlabel('Low-pass corner (Hz)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = np.power(2.0,-14)\n",
    "#f = np.power(2.0,np.arange(-13,-1))\n",
    "f = np.power(1.2,np.arange(-55,-1))\n",
    "f = f[f<=0.5]\n",
    "f = f[f>fmin*2]\n",
    "f = np.append(f,1.0)\n",
    "print(f)\n",
    "print(fmin)\n",
    "\n",
    "plt.figure()\n",
    "for ncorners in range(6):\n",
    "    a = []\n",
    "    for fmax in f:\n",
    "        tr2 = tr.copy()\n",
    "        if fmax<1.0:\n",
    "            #print(fmin)\n",
    "            tr2.filter('bandpass',freqmin=fmin, freqmax=fmax,corners=ncorners+1)\n",
    "            \n",
    "        else:\n",
    "            tr2.filter('highpass',freq=fmin, corners=ncorners+1)\n",
    "        a.append(np.max(np.abs(tr2.data)))\n",
    "    labstr = \"%d corners\" % (ncorners+1)\n",
    "    plt.semilogx(f,a,label=labstr)\n",
    "plt.ylabel('Pa')\n",
    "plt.xlabel('High-pass corner (Hz)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2=msvf[0].copy()\n",
    "pre_filt = [0.0001, 0.0002, 0.5, 0.1]\n",
    "tr2.filter('bandpass', freqmin=0.0001, freqmax=0.5, corners=2)\n",
    "tr2.remove_response(inventory=inv, plot=True, water_level=60)\n",
    "#tr2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2=msvf[0].copy()\n",
    "tr2.plot()\n",
    "pre_filt = [0.0001, 0.0002, 0.25, 0.5]\n",
    "#tr2.filter('pass', freq=0.0001, corners=2)\n",
    "tr2.remove_response(inventory=inv, pre_filt=pre_filt, plot=True, water_level=60)\n",
    "tr2.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseedfile = os.path.join(DATA_ROOT, 'rboom_HDF_within_180_degrees.mseed')\n",
    "inv = obspy.read_inventory(os.path.join(DATA_ROOT, 'rboom_HDF_within_180_degrees.xml'))\n",
    "pre_filt = [0.0001, 0.0002, 0.25, 0.5]\n",
    "N = 1000\n",
    "count = 0\n",
    "f = open(os.path.join(DATA_ROOT, 'rboom_good_HDF_ids_within_180_degrees.pkl'), \"rb\")\n",
    "good_ids = pickle.load(f)\n",
    "f.close()\n",
    "good_st = obspy.core.Stream()\n",
    "more_good = ['S89A5', 'R160F', 'RC93C', 'RA8D4', 'R9606', 'R40C1', 'R3A8A', 'R571C', 'R9CDF', 'RB83C', 'R0033']\n",
    "for sta in more_good:\n",
    "    good_ids.append('AM.%s.00.HDF' % sta)\n",
    "import obspy\n",
    "import io\n",
    "\n",
    "reclen = 512\n",
    "chunksize = 100000 * reclen # Around 50 MB\n",
    "\n",
    "with io.open(mseedfile, \"rb\") as fh:\n",
    "    while count<N:\n",
    "        with io.BytesIO() as buf:\n",
    "            c = fh.read(chunksize)\n",
    "            if not c:\n",
    "                break\n",
    "            buf.write(c)\n",
    "            buf.seek(0, 0)\n",
    "            st = obspy.read(buf)\n",
    "            count+=1\n",
    "        # Do something useful!\n",
    "        st.merge()\n",
    "        for tr in st:\n",
    "            if tr.id in good_ids:\n",
    "                good_st.append(tr)\n",
    "        #st.remove_response(inventory=inv, pre_filt=pre_filt, plot=True, water_level=60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_good = good_st.copy()\n",
    "st_good.taper(0.01)\n",
    "for tr in st_good:\n",
    "    try:\n",
    "        tr.filter('highpass', freq=0.0001, corners=2)\n",
    "    except:\n",
    "        pass\n",
    "st_good = manually_select_good_traces(st_good) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st.select(station='MSVF').plot()\n",
    "pre_filt = [0.001, 0.002, 0.25, 0.5]\n",
    "inv = obspy.read_inventory(os.path.join(DATA_ROOT, 'rboom_HDF_within_180_degrees.xml'))\n",
    "st_good2 = st_good.copy()\n",
    "for tr in st_good2:\n",
    "    #tr.remove_response(inventory=inv, pre_filt=pre_filt, plot=True, water_level=60)\n",
    "    tr.remove_response(inventory=inv, pre_filt=pre_filt, plot=True, water_level=60)\n",
    "    tr.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = good_st.copy()[0]\n",
    "tr.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.trim(starttime=obspy.UTCDateTime(2022,1,15,18,0,0), endtime=obspy.UTCDateTime(2022,1,15,23,0,0))\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.remove_response(inventory=inv, pre_filt=[0.01, 0.02, 10, 20], plot=True, water_level=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ldo3 = inv_ldo2.copy()\n",
    "inv_ldo3.__add__(inv_ldf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inv(inv_ldo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_ldo.select(station='MSVF')[0].stats.distance_in_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inv(inv_ldo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchRadiusDeg = 20\n",
    "fmin = 0.0001\n",
    "T = 1.0/fmin\n",
    "\n",
    "# location of Hunga-Tonga Hunga-Ha'apai\n",
    "olat = -(20 + 34/60 + 12 /3600) \n",
    "olon = -(175 + 22/60 + 48/3600)\n",
    "otime = obspy.core.UTCDateTime('2022-01-15T04:14:45.000000Z') # main eruption time - on day 2\n",
    "\n",
    "startt = otime - T*2\n",
    "endt = otime + 7 * 3600 + T*2 \n",
    "\n",
    "fdsnURL = \"http://service.iris.edu\"\n",
    "chanstring = 'HHZ'\n",
    "st_hhz, inv_hhz = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st=st_hhz.copy()\n",
    "st.taper(0.1)\n",
    "st.filter('bandpass', freqmin=0.01, freqmax=1.0, corners=2)\n",
    "st.trim(starttime=obspy.UTCDateTime(2022,1,15,4,14,45),endtime=obspy.UTCDateTime(2022,1,15,7,14,45))\n",
    "st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in st_hhz:\n",
    "    print(tr.stats.distance_in_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.trim(starttime=obspy.UTCDateTime(2022,1,15,6,53,0),endtime=obspy.UTCDateTime(2022,1,15,6,57,0))\n",
    "st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanstring = 'BHZ'\n",
    "st_bhz, inv_bhz = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=st_bhz.copy()\n",
    "st.taper(0.1)\n",
    "st.filter('bandpass', freqmin=0.01, freqmax=15.0, corners=2)\n",
    "st.trim(starttime=obspy.UTCDateTime(2022,1,15,4,14,45),endtime=obspy.UTCDateTime(2022,1,15,4,24,45))\n",
    "st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchRadiusDeg = 60\n",
    "fmin = 0.001\n",
    "T = 1.0/fmin\n",
    "\n",
    "# location of Hunga-Tonga Hunga-Ha'apai\n",
    "olat = -(20 + 34/60 + 12 /3600) \n",
    "olon = -(175 + 22/60 + 48/3600)\n",
    "otime = obspy.core.UTCDateTime('2022-01-15T04:14:45.000000Z') # main eruption time - on day 2\n",
    "\n",
    "distkm = degrees2kilometers(searchRadiusDeg)\n",
    "max_acoustic_speed = 380\n",
    "min_acoustic_speed = 300\n",
    "min_travel_time = distkm * 1000 / max_acoustic_speed \n",
    "max_travel_time = distkm * 1000 / min_acoustic_speed                   \n",
    "print(searchRadiusDeg, distkm, max_travel_time, min_travel_time)\n",
    "\n",
    "startt = otime - T*2\n",
    "endt = otime + max_travel_time + T*2 \n",
    "\n",
    "fdsnURL = \"http://service.iris.edu\"\n",
    "chanstring = 'LHZ'\n",
    "st_lhz, inv_lhz = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_lhz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = st_lhz.copy()\n",
    "st.taper(0.1)\n",
    "st.filter('bandpass', freqmin=0.003, freqmax=0.5, corners=2)\n",
    "st.trim(starttime=obspy.UTCDateTime(2022,1,15,4,0,0),endtime=obspy.UTCDateTime(2022,1,15,5,0,0))\n",
    "for tr in st:\n",
    "    tr.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st.select(station='MSVF').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr = obspy.core.Trace()\n",
    "tr.data = st[0].data + st[1].data\n",
    "tr.stats.starttime = st[0].stats.starttime\n",
    "tr.stats.sampling_rate = st[0].stats.sampling_rate\n",
    "tr.id = 'XX.MSVF.20.LHZ'\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr.trim(starttime=obspy.UTCDateTime(2022,1,15,4,15,0),endtime=obspy.UTCDateTime(2022,1,15,4,35,0))\n",
    "tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdsnClient = Client(fdsnURL)  \n",
    "startt = otime-10000\n",
    "endt = obspy.UTCDateTime(2022,1,15,7,0,0)+10000\n",
    "\n",
    "msvf = fdsnClient.get_waveforms('II', 'MSVF', '*', '*', startt, endt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for loc in ['00', '10']:\n",
    "    st = msvf.select(location=loc, channel='[LV][HD]?')\n",
    "    st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tr in msvf:\n",
    "    print(tr.id, tr.stats.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in ['00', '10']:\n",
    "    st = msvf.copy().select(location=loc, channel='[LV][HD]?')\n",
    "    st.detrend('linear')\n",
    "    st.taper(0.02)\n",
    "    st.filter('bandpass',freqmin=0.0002,freqmax=0.01)\n",
    "    st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msvf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for loc in ['00', '10']:\n",
    "    st = msvf.copy().select(location=loc, channel='B[HD]?')\n",
    "    st.detrend('linear')\n",
    "    st.taper(0.02)\n",
    "    st.filter('highpass',freq=0.5,corners=2)\n",
    "    st.trim(starttime=otime+150,endtime=otime+300)\n",
    "    st.plot(equal_scale=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchRadiusDeg = 120\n",
    "fmin = 0.001\n",
    "T = 1.0/fmin\n",
    "\n",
    "# location of Hunga-Tonga Hunga-Ha'apai\n",
    "olat = -(20 + 34/60 + 12 /3600) \n",
    "olon = -(175 + 22/60 + 48/3600)\n",
    "otime = obspy.core.UTCDateTime('2022-01-15T04:14:45.000000Z') # main eruption time - on day 2\n",
    "\n",
    "distkm = degrees2kilometers(searchRadiusDeg)\n",
    "max_acoustic_speed = 380\n",
    "min_acoustic_speed = 300\n",
    "min_travel_time = distkm * 1000 / max_acoustic_speed \n",
    "max_travel_time = distkm * 1000 / min_acoustic_speed                   \n",
    "print(searchRadiusDeg, distkm, max_travel_time, min_travel_time)\n",
    "\n",
    "startt = otime - T*2\n",
    "endt = otime + max_travel_time + T*2 \n",
    "\n",
    "fdsnURL = \"http://service.iris.edu\"\n",
    "chanstring = 'LHZ'\n",
    "st_lhz, inv_lhz = analyze_clientchan(fdsnURL, chanstring, fmin=fmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_ldf_recon = obspy.read(os.path.join(DATA_ROOT, 'iris_LDF_within_180_degrees.mseed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(st_ldf_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(st_ldf_recon.merge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for tr in st_ldf_recon:\n",
    "    if not tr.id in ids:\n",
    "        ids.append(tr.id)\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_ldo_recon = obspy.read(os.path.join(DATA_ROOT, 'iris_LDO_within_180_degrees.mseed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for tr in st_ldo_recon:\n",
    "    if not tr.id in ids:\n",
    "        ids.append(tr.id)\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "757000/340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2226/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
