{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "square-cambodia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./AAA-master/config/specific/usecase1_continuous_classification/usecase1_EXAMPLE.json\n",
      "Welcome to this automatic analysis architecture\n",
      "Copyright: Marielle MALFANTE - GIPSA-Lab\n",
      "Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, 38000 Grenoble, France\n",
      "\n",
      " *** PROJECT CONFIGURATION 10 ***  \n",
      "Configuration object from <path> ./AAA-master/config/general/newsettings_10.json, <configuration_number> 10,\n",
      " <general> {'project_root': './AAA-master/', 'analysis_type': 'continuous', 'path_to_specific_settings_file': 'config/specific/usecase1_continuous_classification/usecase1_EXAMPLE.json', 'path_to_res': 'res/', 'path_to_visuals': 'fig/', 'path_to_res_to_review': 'res_to_review/'},\n",
      " <application> {'name': 'montserrat'},\n",
      " <preprocessing> {'energy_norm': True},\n",
      " <learning> {'algo': RandomForestClassifier(criterion='entropy'), 'cv': StratifiedShuffleSplit(n_splits=50, random_state=None, test_size=0.3,\n",
      "            train_size=0.7), 'path_to_catalogue': 'catalog/30_MVO_labelled_events_filtered.pd'},\n",
      " <features> {'path_to_config': 'config/specific/features/features_01.json', 'computation_domains': 'time spectral cepstral', 'thresholding': True, 'thresholds': [0.8, 0.8, 0.8, 0.8, 0.8]},\n",
      " <data_to_analyze> {'path_to_data': './miniseed_c', 'data_files': '*.mseed', 'reading_function': <function read_montserrat at 0x7ff8d299b430>, 'reading_arguments': {}},\n",
      " <analysis> {'n_window': 1, 'window_length': 120.0, 'delta': 100, 'bandwidth': {'f_min': [0.5], 'f_max': [25]}, 'butter_order': 2, 'spectro_window_size': 256, 'f_max': 25, 'nBands': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "################################\n",
    "# General setup                #\n",
    "################################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "sys.path.insert(0, './AAA-master/automatic_processing')\n",
    "from config import Config\n",
    "from features import FeatureVector\n",
    "from tools import extract_features\n",
    "import obspy\n",
    "import datetime\n",
    "\n",
    "### PREPARE THE CATALOG DataFrame ###\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO') # e.g. /home/user/seismo\n",
    "pandaSeisDir = os.path.join(SEISAN_DATA, 'miniseed_c') # e.g. /home/user/seismo/pandaSeis\n",
    "SEISAN_DB = 'MVOE_' # e.g. the seisan database name (e.g. MVOE_)\n",
    "PROJECTDIR = os.path.join(os.getenv('HOME'),'src', 'kitchensinkGT', 'PROJECTS', 'MontserratML') # this dir\n",
    "csvfile_external = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB, 'runAAA', 'MVOE_11_labelled_events.csv')\n",
    "csvfile_internal = 'catalog/30_MVO_labelled_events_filtered.csv' # has to match that in AAA-master/config/general/newsettings_10.json\n",
    "csvfile_internal = './AAA-master/MONTSERRAT/' + csvfile_internal\n",
    "output_path_cat = csvfile_internal.replace('.csv', '.pd')\n",
    "alltraces_file = '30_alltraceDFs.csv'\n",
    "\n",
    "metrics_to_add = ['bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]', \\\n",
    "                  'bw_max', 'bw_min', 'kurtosis', 'skewness', 'peakF', 'medianF']\n",
    "\n",
    "# Change if you want your screen to keep quiet\n",
    "# 0 = quiet\n",
    "# 1 = in between\n",
    "# 2 = detailed information\n",
    "verbatim = 1\n",
    "\n",
    "# Init project with configuration file\n",
    "config = Config('./AAA-master/config/general/newsettings_10.json', verbatim=verbatim)\n",
    "config.readAndCheck()  \n",
    "cat = pd.read_csv(csvfile_internal)\n",
    "\n",
    "# Get or define usefull stuff\n",
    "features = FeatureVector(config, verbatim=verbatim)\n",
    "\n",
    "# Save featuresList to pickle file\n",
    "if not os.path.isdir('features'):\n",
    "    os.makedirs('features')\n",
    "        \n",
    "# Glenn. path has miniseed_c hardcoded at start. I want to change this to whatever the config says\n",
    "WAVTOPDIR = config.data_to_analyze['path_to_data'] \n",
    "\n",
    "# read catalog \n",
    "for i in range(len(cat.index)):\n",
    "    if verbatim > 1:\n",
    "        print('Processing waveform %d of %d' % (i, catalog_length))\n",
    "    secondFloat = cat.iloc[i]['second']\n",
    "    tStartSignature = datetime.datetime(int(cat.iloc[i]['year']),     \\\n",
    "                                        int(cat.iloc[i]['month']),    \\\n",
    "                                        int(cat.iloc[i]['day']),      \\\n",
    "                                        int(cat.iloc[i]['hour']),     \\\n",
    "                                        int(cat.iloc[i]['minute']),   \\\n",
    "                                        int(secondFloat), \\\n",
    "                                        int((secondFloat-int(secondFloat))*1000000)) #microseconds\n",
    "    duration = cat.iloc[i]['length']\n",
    "    mseedpath = cat.iloc[i]['path']     \n",
    "    mseedpath = mseedpath.replace('miniseed_c', WAVTOPDIR)\n",
    "    mseedbase = os.path.basename(mseedpath)\n",
    "    \n",
    "    # check is MSEED file exists. copy it to local if do not have already. read it.\n",
    "    mseedlocal = mseedpath.replace('miniseed_c', 'miniseed_c_local')\n",
    "    if not os.path.isfile(mseedpath):        \n",
    "        print(\"File not found: \",mseedpath)\n",
    "        continue\n",
    "    else:\n",
    "        mseedlocaldir = os.path.dirname(mseedlocal)\n",
    "        if not os.path.isdir(mseedlocaldir):\n",
    "            os.makedirs(mseedlocaldir)\n",
    "        os.system('cp %s %s' % (mseedpath, mseedlocal))\n",
    "\n",
    "        # SCAFFOLD, JUST TO GET DATA\n",
    "        continue\n",
    "        \n",
    "        print('Reading ',mseedpath)\n",
    "        st = obspy.read(mseedpath)\n",
    "        \n",
    "    ###### SPIKES CHECK - won't be needed when we reprocess all data #####\n",
    "    # The reason we do the spike check on the raw WAV file is \n",
    "    # because filters run to produce the MSEED file distort the spike\n",
    "    wavpath = mseedpath.replace('miniseed_c', 'WAV').replace('.mseed','')\n",
    "    rawst = read(wavpath)\n",
    "    for tr in rawst:\n",
    "        check_for_spikes(tr)\n",
    "\n",
    "    good_traces = 0\n",
    "    trace_ids_to_eliminate = []\n",
    "    fix_trace_id(rawst)\n",
    "    for tr in rawst:\n",
    "        check_for_spikes(tr)\n",
    "        if tr.stats.quality_factor > 1.0:\n",
    "            good_traces += 1\n",
    "        else:\n",
    "            trace_ids_to_eliminate.append(tr.id)\n",
    "\n",
    "    for tr in st:\n",
    "        if tr.id in trace_ids_to_eliminate:\n",
    "            st.remove(tr)\n",
    "    ################ END OF SPIKES CHECK ########################\n",
    "    \n",
    "    if len(st)==0:\n",
    "        continue\n",
    "        \n",
    "    tracecsv = mseedpath.replace('.mseed','.csv')\n",
    "    if os.path.isfile(tracecsv):\n",
    "        print('Reading ',tracecsv)\n",
    "        tracedf = pd.read_csv(tracecsv)\n",
    "    else:\n",
    "        print(tracecsv, ' not found')\n",
    "        continue\n",
    "    \n",
    "    for tr in st:\n",
    "        print('Processing ', tr.id)\n",
    "        featurespkl = os.path.join('features',mseedbase.replace('.mseed', '.%s.pkl' % tr.id)) \n",
    "        if os.path.exists(featurespkl):\n",
    "            print(featurespkl, ' exists. Skipping')\n",
    "            continue\n",
    "        \n",
    "        # Get information about recording\n",
    "        fs = tr.stats['sampling_rate']         \n",
    "        length_n = tr.stats['npts'] # only change from read_ubinas\n",
    "        \n",
    "        if fs < 70.0 or length_n < 1000:\n",
    "            continue         \n",
    "\n",
    "        # Preprocessing & features extraction\n",
    "        y = [tr.data]\n",
    "        featuresList = extract_features(config, y, features, fs)\n",
    "        \n",
    "        # THIS WOULD BE THE PLACE TO ADD THE PRECOMPUTED FEATURES FROM SEISAN2PANDAS\n",
    "        thistracedf = tracedf[tracedf['id']==tr.id]\n",
    "        for col in metrics_to_add:\n",
    "            featuresList = np.append(featuresList, thistracedf[col])\n",
    "        bandwidth = thistracedf['bw_max'] - thistracedf['bw_min']\n",
    "        featuresList = np.append(featuresList, bandwidth)\n",
    "        \n",
    "        print('Writing ',featurespkl)\n",
    "        with open(featurespkl, 'wb') as f:\n",
    "            pickle.dump(featuresList, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-newcastle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
