{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montserrat event selector for Machine Learning\n",
    "The aim of this code is to find the best N events of each type, and create a corresponding CSV file and data structure for entry into Alexis' and Marielle's AAA codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed events: Marked to:\n",
      "- split  13\n",
      "- delete  2\n",
      "- ignore  27\n",
      "Catalog down from 17496 to 17454 events\n",
      " \n",
      " \n",
      "Now we have the following number of events by subclass:\n",
      "- D: 0\n",
      "- R: 5\n",
      "- r: 114\n",
      "- e: 93\n",
      "- l: 106\n",
      "- h: 107\n",
      "- t: 102\n",
      "Eliminating subclass R\n",
      "The subclasses for machine learning are Drelht.\n",
      "Removed subclasses R\n",
      "Here is the FINAL list of events by subclass and whether they have been checked:\n",
      "Event counts:\n",
      "Checked events: 522\n",
      "new_subclass\n",
      "e     93\n",
      "h    107\n",
      "l    106\n",
      "r    114\n",
      "t    102\n",
      "Name: path, dtype: int64\n",
      "Events by weight / quality threshold\n",
      "weight\n",
      "1.0     33\n",
      "2.0     25\n",
      "3.0     45\n",
      "4.0     22\n",
      "5.0     47\n",
      "6.0     76\n",
      "7.0     93\n",
      "8.0     77\n",
      "9.0     90\n",
      "10.0    12\n",
      "11.0     1\n",
      "12.0     1\n",
      "Name: path, dtype: int64\n",
      "Catalog CSV saved to  MVO_labelled_events.csv\n",
      "total checked events = 584\n",
      "total classified events = 542\n",
      "D 0\n",
      "R 5\n",
      "r 114\n",
      "e 93\n",
      "l 106\n",
      "h 107\n",
      "t 102\n",
      "total events matching ML subclasses = 527\n",
      "total reclassified events = 115\n",
      "total already correctly classified events = 412\n",
      "Error rate = 21.8%\n",
      "527 527\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "LIBpath = os.path.join( os.getenv('HOME'),'src','kitchensinkGT', 'LIB')\n",
    "sys.path.append(LIBpath)\n",
    "from libseisGT import add_to_trace_history #, mulplt\n",
    "from modutils import yn_choice\n",
    "\n",
    "from obspy import read_inventory #, remove_response\n",
    "from libMVO import fix_trace_id, inventory_fix_id_mvo, load_mvo_inventory\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(cwd)\n",
    "from libMontyML import read_volcano_def, build_master_event_catalog, parse_STATION0HYP, qc_event, \\\n",
    "     get_weighted_fingerprints, save_fingerprints, remove_marked_events, to_AAA, report_checked_events\n",
    "\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO')\n",
    "DB = 'MVOE_'\n",
    "\n",
    "subclass_mapping = read_volcano_def() # subclasses allowed for classification\n",
    "seisan_subclasses = subclass_mapping['subclass'].values.tolist() # append('g') as needed, it is not an allowed subclass\n",
    "#seisan_etypes = subclass_mapping['etype'].values.tolist()\n",
    "subclasses_for_ML = ['D', 'R', 'r', 'e', 'l', 'h', 't'] # subclasses allowed for Machine Learning\n",
    "outfile = 'catalog_all.csv'\n",
    "\n",
    "if os.path.exists(outfile):\n",
    "    dfall = pd.read_csv(outfile) # how do i ignore the index?\n",
    "    # do the following until I learn how to ignore index. otherwise it adds a new column on each load.\n",
    "    dfall = dfall[['filetime', 'Fs', 'RSAM_high',\n",
    "       'RSAM_low', 'band_ratio', 'bw_max', 'bw_min', 'calib', 'cft_peak_wmean',\n",
    "       'cft_std_wmean', 'coincidence_sum', 'day', 'detection_quality',\n",
    "       'energy', 'hour', 'kurtosis', 'medianF', 'minute', 'month', 'num_gaps',\n",
    "       'num_traces', 'offtime', 'ontime', 'path', 'peakA', 'peakF', 'peakamp',\n",
    "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
    "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
    "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
    "       'sfile', 'skewness', 'starttime', 'subclass', 'trigger_duration',\n",
    "       'twin', 'year', 'D', 'R', 'r', 'e', 'l', 'h', 't', 'new_subclass',\n",
    "       'weight', 'checked', 'split', 'delete', 'ignore']]\n",
    "else:\n",
    "    master_event_catalog = 'catalog_all_original.csv'\n",
    "    dfall = build_master_event_catalog(SEISAN_DATA, DB, master_event_catalog, subclasses_for_ML)\n",
    "\n",
    "station0hypfile = os.path.join(SEISAN_DATA, 'DAT', 'STATION0_MVO.HYP')\n",
    "station_locationsDF = parse_STATION0HYP(station0hypfile)\n",
    "\n",
    "###\n",
    "#fingerprints = get_weighted_fingerprints(dfall, subclasses_for_ML, N=300, exclude_checked=False)\n",
    "#one_event_df, quit = qc_event(dfall, subclasses_for_ML, seisan_subclasses, fingerprints, SEISAN_DATA, station_locationsDF)\n",
    "\n",
    "iterate_again = False # changed this back to do the loop\n",
    "while iterate_again:\n",
    "\n",
    "    # get/update the fingerprints of each event class\n",
    "    fingerprints = get_weighted_fingerprints(dfall, subclasses_for_ML, N=300, exclude_checked=False)\n",
    "    save_fingerprints(fingerprints, subclasses_for_ML)\n",
    "    \n",
    "    # manually QC the next event. each time we choose the class with least checked examples\n",
    "    one_event_df, quit = qc_event(dfall, subclasses_for_ML, seisan_subclasses, fingerprints, SEISAN_DATA, station_locationsDF)\n",
    "    if isinstance(one_event_df, pd.DataFrame):\n",
    "        # now we must merge this back into dfall\n",
    "        dfall.sort_index(inplace=True)\n",
    "        dfall.update(one_event_df)  \n",
    "    \n",
    "        # save the data  \n",
    "        dfall.to_csv(outfile, index=False)\n",
    "    else:\n",
    "        iterate_again=False\n",
    "    if quit:\n",
    "        iterate_again=False \n",
    "# remove events we marked for deletion, splitting or to ignore\n",
    "dfsubset = remove_marked_events(dfall)\n",
    "\n",
    "aaa_infile = 'MVO_labelled_events.csv' \n",
    "COPYDIR = os.path.join(os.getenv('HOME'),'Dropbox','MVO_labelled_events')\n",
    "to_AAA(dfsubset, subclasses_for_ML, aaa_infile, SEISAN_DATA, ignore_extra_columns=False)\n",
    "report_checked_events(dfall, subclasses_for_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
