{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "################################\n",
    "# General setup                #\n",
    "################################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "sys.path.insert(0, './AAA-master/automatic_processing')\n",
    "#import tools\n",
    "from config import Config\n",
    "#from analyzer import Analyzer\n",
    "\n",
    "import json\n",
    "from os.path import isfile, isdir\n",
    "import datetime\n",
    "from features import FeatureVector\n",
    "from tools import butter_bandpass_filter\n",
    "from featuresFunctions import energy, energy_u\n",
    "from math import sqrt\n",
    "from tools import print_cm\n",
    "import time\n",
    "from tools import extract_features\n",
    "from copy import deepcopy\n",
    "\n",
    "### PREPARE THE CATALOG DataFrame ###\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO') # e.g. /home/user/seismo\n",
    "pandaSeisDir = os.path.join(SEISAN_DATA, 'miniseed_c') # e.g. /home/user/seismo/pandaSeis\n",
    "SEISAN_DB = 'MVOE_' # e.g. the seisan database name (e.g. MVOE_)\n",
    "PROJECTDIR = os.path.join(os.getenv('HOME'),'src', 'kitchensinkGT', 'PROJECTS', 'MontserratML') # this dir\n",
    "csvfile_external = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB, 'runAAA', 'MVOE_11_labelled_events.csv')\n",
    "csvfile_internal = 'catalog/30_MVO_labelled_events_filtered.csv' # has to match that in AAA-master/config/general/newsettings_10.json\n",
    "csvfile_internal = './AAA-master/MONTSERRAT/' + csvfile_internal\n",
    "output_path_cat = csvfile_internal.replace('.csv', '.pd')\n",
    "alltraces_file = '30_alltraceDFs.csv'\n",
    "\n",
    "metrics_to_add = ['bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]', \\\n",
    "                  'bw_max', 'bw_min', 'kurtosis', 'skewness', 'peakF', 'medianF']\n",
    "\n",
    "# Change if you want your screen to keep quiet\n",
    "# 0 = quiet\n",
    "# 1 = in between\n",
    "# 2 = detailed information\n",
    "verbatim = 1\n",
    "\n",
    "# Init project with configuration file\n",
    "config = Config('./AAA-master/config/general/newsettings_10.json', verbatim=verbatim)\n",
    "config.readAndCheck()  \n",
    "cat = pd.read_csv(csvfile_internal)\n",
    "\n",
    "# Get or define usefull stuff\n",
    "features = FeatureVector(config, verbatim=verbatim)\n",
    "nData = len(self.catalogue.index)\n",
    "if returnData:\n",
    "    allData = np.zeros((nData,),dtype=object)\n",
    "allLabels = np.zeros((nData,),dtype=object)\n",
    "allFeatures = np.zeros((nData,features.n_domains*features.n_features),dtype=float)\n",
    "\n",
    "# Read all labeled signatures (labels+data) from the catalogue, and extract features\n",
    "tStart = time.time()\n",
    "catalog_length = len(cat.index)\n",
    "\n",
    "# Save featuresList to pickle file\n",
    "if not os.path.exists('features'):\n",
    "    os.makedirs('features')\n",
    "        \n",
    "# read catalog         \n",
    "WAVTOPDIR = config.data_to_analyze['path_to_data'] # Glenn. path has miniseed_c hardcoded at start. I want to change this to whatever the config says\n",
    "for i in range(catalog_length):\n",
    "    if verbatim > 1:\n",
    "        print('Processing waveform %d of %d' % (i, catalog_length))\n",
    "    secondFloat = cat.iloc[i]['second']\n",
    "    tStartSignature = datetime.datetime(int(cat.iloc[i]['year']),     \\\n",
    "                                        int(cat.iloc[i]['month']),    \\\n",
    "                                        int(cat.iloc[i]['day']),      \\\n",
    "                                        int(cat.iloc[i]['hour']),     \\\n",
    "                                        int(cat.iloc[i]['minute']),   \\\n",
    "                                        int(secondFloat), \\\n",
    "                                        int((secondFloat-int(secondFloat))*1000000)) #microseconds\n",
    "    duration = cat.iloc[i]['length']\n",
    "    path = cat.iloc[i]['path']     \n",
    "    path = path.replace('miniseed_c', WAVTOPDIR)\n",
    "\n",
    "    # Get label and check that it is single label (multi label not supported yet)\n",
    "    lab = cat.iloc[i]['class']\n",
    "    if type(lab) is list:\n",
    "        print('Multi label not implemented for learning yet')\n",
    "        return None\n",
    "    allLabels[i] = lab\n",
    "\n",
    "    # LOAD WAVEFORM\n",
    "    #(fs, signature) = requestObservation(config, tStartSignature, duration, path, verbatim=0)\n",
    "    # first check for features file\n",
    "\n",
    "    # what traceID are we looking for - should figure out how to write this into the config\n",
    "    fptr = open('./AAA-master/MONTSERRAT/current_traceID.txt','r')\n",
    "    traceID = fptr.read()\n",
    "    fptr.close()      \n",
    "\n",
    "    # NEED TO LOAD DATA - FIRST CHECK IF FEATURES ALREADY COMPUTED\n",
    "    mseedbase = os.path.basename(path)\n",
    "    \n",
    "    # first check for features file\n",
    "    if not isfile(path):\n",
    "        \n",
    "        # look for WAV file instead, which lacks the .mseed extension\n",
    "        path_wav = path.replace('.mseed','')\n",
    "        if not isfile(path_wav): \n",
    "            print(\"File not found: \",path)\n",
    "            return None, None\n",
    "        else:\n",
    "            st = obspy.read(path_wav)\n",
    "            fix_trace_id(stream)\n",
    "    else:\n",
    "        st = obspy.read(path)\n",
    "        \n",
    "    # ADD ANY NEW CHECKS HERE, e.g. THE SPIKES CHECK\n",
    "    \n",
    "    if len(st)>0:\n",
    "        tracecsv = path.replace('.mseed','.csv')\n",
    "        if isfile(tracecsv):\n",
    "            tracedf = pd.read_csv(tracecsv)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    for tr in st:\n",
    "        featurespkl = os.path.join('features',mseedbase.replace('.mseed', '.%s.pkl' % tr.id)) \n",
    "        if os.path.exists(featurespkl):\n",
    "            continue\n",
    "        \n",
    "        # Get signal and its metadata\n",
    "        s_dict = tr.stats\n",
    "        \n",
    "        # Get information about recording\n",
    "        fs = tr.stats['sampling_rate']         \n",
    "        length_n = tr.stats['npts'] # only change from read_ubinas\n",
    "        #d0 = s_dict['starttime']\n",
    "        #d1 = s_dict['endtime']\n",
    "        #t_start = datetime.datetime(d0.year,d0.month,d0.day,d0.hour,d0.minute,d0.second)\n",
    "        #t_end = datetime.datetime(d1.year,d1.month,d1.day,d1.hour,d1.minute,d1.second)\n",
    "        \n",
    "        if fs < 70.0 or length_n < 1000:\n",
    "            continue         \n",
    "\n",
    "        # Preprocessing & features extraction\n",
    "        featuresList = extract_features(config, tr.data, features, fs)\n",
    "        \n",
    "        # THIS WOULD BE THE PLACE TO ADD THE PRECOMPUTED FEATURES FROM SEISAN2PANDAS\n",
    "        thistracedf = tracedf[tracedf['id']==tr.id]\n",
    "        for col in metrics_to_add:\n",
    "            featuresList.append(thistracedf[col])\n",
    "        bandwidth = thistracedf['bw_max'] - thistracedf['bw_min']\n",
    "        featuresList.append(bandwidth)\n",
    "        \n",
    "        with open(featurespkl, 'wb') as f:\n",
    "            pickle.dump(featuresList, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
