{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reconcile reawav_MVOE_all.csv (concatenated reawav_MVOE_YYYYMM.csv) on hal9000 against catalog_unique.csv which came from processing in Paris \n",
    "# on my laptop.\n",
    "\n",
    "# Need to merge the new_subclass, weight, checked, split, delete and ignore columns.\n",
    "# Should probably match on the WAVfile path.\n",
    "# Do I need to merge D, R, r, e, l, h and t columns?\n",
    "\n",
    "# Previously suggested workflow:\n",
    "import pandas as pd\n",
    "import os\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO')\n",
    "SEISAN_DB = 'MVOE_'\n",
    "import sys\n",
    "sys.path.append('../obsolete')\n",
    "\n",
    "from libMontyML import build_master_event_catalog\n",
    "\n",
    "subclasses_for_ML = ['D', 'R', 'r', 'e', 'l', 'h', 't']\n",
    "dfall1 = build_master_event_catalog(SEISAN_DATA, SEISAN_DB, 'MVOE_catalog_original_hal.csv', subclasses_for_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filetime', 'Fs', 'RSAM_high', 'RSAM_low', 'band_ratio', 'bw_max',\n",
      "       'bw_min', 'calib', 'cft_peak_wmean', 'cft_std_wmean', 'coincidence_sum',\n",
      "       'day', 'detection_quality', 'energy', 'hour', 'kurtosis', 'medianF',\n",
      "       'minute', 'month', 'num_gaps', 'num_traces', 'offtime', 'ontime',\n",
      "       'path', 'peakA', 'peakF', 'peakamp', 'peaktime', 'percent_availability',\n",
      "       'quality', 'sample_lower_quartile', 'sample_max', 'sample_mean',\n",
      "       'sample_median', 'sample_min', 'sample_rms', 'sample_stdev',\n",
      "       'sample_upper_quartile', 'second', 'sfile', 'skewness', 'starttime',\n",
      "       'subclass', 'trigger_duration', 'twin', 'year', 'D', 'R', 'r', 'e', 'l',\n",
      "       'h', 't', 'new_subclass', 'weight', 'checked', 'split', 'delete',\n",
      "       'ignore', 'mainclass'],\n",
      "      dtype='object')\n",
      "17489\n",
      "Index(['Fs', 'Unnamed: 0', 'Unnamed: 0.1', 'bandratio_[0.8_4.0_16.0]',\n",
      "       'bandratio_[1.0_6.0_11.0]', 'bw_max', 'bw_min', 'calib',\n",
      "       'cft_peak_wmean', 'cft_std_wmean', 'coincidence_sum', 'day',\n",
      "       'detection_quality', 'energy', 'hour', 'kurtosis', 'medianF', 'minute',\n",
      "       'month', 'noise_level', 'num_gaps', 'num_traces', 'offtime', 'ontime',\n",
      "       'path', 'peakA', 'peakF', 'peakamp', 'peaktime', 'percent_availability',\n",
      "       'quality', 'sample_lower_quartile', 'sample_max', 'sample_mean',\n",
      "       'sample_median', 'sample_min', 'sample_rms', 'sample_stdev',\n",
      "       'sample_upper_quartile', 'second', 'sfile', 'signal_level', 'skewness',\n",
      "       'snr', 'subclass', 'trigger_duration', 'year', 'D', 'R', 'r', 'e', 'l',\n",
      "       'h', 't', 'new_subclass', 'weight', 'checked', 'split', 'delete',\n",
      "       'ignore'],\n",
      "      dtype='object')\n",
      "222499\n"
     ]
    }
   ],
   "source": [
    "old_checked_csv = \"../CSVfiles/catalog_unique.csv\"\n",
    "old_checked_cat = pd.read_csv(old_checked_csv)\n",
    "\n",
    "# seems here I am running into an issue here where ../CSVfiles/catalog_unique.csv is not actually my final \n",
    "# catalog from Paris, as it seems to be in some earlier, intermediate format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filetime', 'RSAM_high', 'RSAM_low', 'band_ratio', 'starttime', 'twin', 'mainclass']\n",
      "['Unnamed: 0', 'Unnamed: 0.1', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]', 'noise_level', 'signal_level', 'snr']\n",
      "Different columns. Cannot update/merge\n"
     ]
    }
   ],
   "source": [
    "# check they have the same index column\n",
    "\n",
    "# check these have the same columns\n",
    "columns_not_in_dfall1 = []\n",
    "columns_not_in_oldcat = []\n",
    "for column in old_checked_cat.columns:\n",
    "    if not column in dfall1.columns:\n",
    "        columns_not_in_dfall1.append(column)\n",
    "for column in dfall1.columns:\n",
    "    if not column in old_checked_cat.columns:\n",
    "        columns_not_in_oldcat.append(column)     \n",
    "print(columns_not_in_dfall1)\n",
    "print(columns_not_in_oldcat)\n",
    "if columns_not_in_dfall1 or columns_not_in_oldcat:\n",
    "    # cannot merge\n",
    "    print('Different columns. Cannot update/merge')\n",
    "else:\n",
    "    # can merge\n",
    "    dfall2 = dfall1.copy()\n",
    "    dfall2.update(old_checked_cat)\n",
    "    print(len(dfall1), len(old_checked_cat), len(dfall2))\n",
    "\n",
    "    dfchecked = dfall2[dfall2['checked']==True]\n",
    "    print(len(dfchecked))\n",
    "\n",
    "    ne = (dfall1 != dfall2).any()\n",
    "    print(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
