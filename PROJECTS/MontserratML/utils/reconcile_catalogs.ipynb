{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge catalogs\n",
    "Reconcile full catalog on hal/newton in Fall 2021 with the incomplete but partially reclassified catalog from my laptop whilst in Paris in July 2021\n",
    "Need to reconcile reawav_MVOE_all.csv (concatenated reawav_MVOE_YYYYMM.csv) on hal9000 against catalog_unique.csv which came from processing in Paris \n",
    "on my laptop.\n",
    "\n",
    "Need to merge the new_subclass, weight, checked, split, delete and ignore columns.\n",
    "Should probably match on the WAVfile path.\n",
    "Do I need to merge D, R, r, e, l, h and t columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gt/opt/anaconda3/envs/AAA/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (0,3,15,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO')\n",
    "SEISAN_DB = 'MVOE_'\n",
    "\n",
    "def fix_df(df):\n",
    "    \"\"\"\n",
    "    correct_columns = ['filetime', 'Fs', 'bandratio_[0.8_4.0_16.0]',\n",
    "       'bandratio_[1.0_6.0_11.0]', 'bw_max', 'bw_min', 'calib',\n",
    "       'cft_peak_wmean', 'cft_std_wmean', 'coincidence_sum', 'day',\n",
    "       'detection_quality', 'energy', 'hour', 'kurtosis', 'medianF', 'minute',\n",
    "       'month', 'noise_level', 'num_gaps', 'num_traces', 'offtime', 'ontime',\n",
    "       'path', 'peakA', 'peakF', 'peakamp', 'peaktime', 'percent_availability',\n",
    "       'quality', 'sample_lower_quartile', 'sample_max', 'sample_mean',\n",
    "       'sample_median', 'sample_min', 'sample_rms', 'sample_stdev',\n",
    "       'sample_upper_quartile', 'second', 'sfile', 'signal_level', 'skewness',\n",
    "       'snr', 'subclass', 'trigger_duration', 'year', 'D', 'R',\n",
    "       'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked', 'split',\n",
    "       'delete', 'ignore'] # removed starttime\n",
    "    subset_columns = []\n",
    "    for column in df.columns:\n",
    "        if column in correct_columns:\n",
    "            subset_columns.append(column)\n",
    "    print(len(subset_columns))\n",
    "    #df = df[subset_columns] # subset to correct columns\n",
    "    #df.set_index('path', inplace=True) # try this\n",
    "    #df.sort_index(inplace=True)   \n",
    "    df2 = df[subset_columns] # subset to correct columns\n",
    "    \"\"\"\n",
    "    good_columns = []\n",
    "    for thiscol in df.columns:\n",
    "        if not 'ntitle' in thiscol:\n",
    "            if not 'Unname' in thiscol:\n",
    "                good_columns.append(thiscol)\n",
    "    df2 = df[good_columns] # subset to correct columns\n",
    "    \n",
    "    \n",
    "    #df3 = df2.set_index('path', inplace=False) # try this\n",
    "    #df4 = df3.sort_index(inplace=False)    \n",
    "    return df2\n",
    "\n",
    "def df2csv_without_index(df, csvfile):\n",
    "    df = df.reset_index()  \n",
    "    df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    df.to_csv(csvfile, index=False)\n",
    "\n",
    "def print_checked_rows(): # not used\n",
    "    rows = []\n",
    "    for i,row in unchecked2.iterrows():\n",
    "        if row['checked']:\n",
    "            rows.append(row)\n",
    "    print(pd.DataFrame(rows))    \n",
    "    \n",
    "#full_unchecked_csv = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB, 'labelling', '%scatalog.csv' % SEISAN_DB)\n",
    "full_unchecked_csv = os.path.join('/Volumes/shareddrive/thompsong', 'MachineLearning', \\\n",
    "                                  SEISAN_DB, 'labelling', '%s11_master_catalog.csv' % SEISAN_DB)\n",
    "\n",
    "\n",
    "full_unchecked_cat = pd.read_csv(full_unchecked_csv)    \n",
    "unchecked = fix_df(full_unchecked_cat)\n",
    "unchecked.head()\n",
    "unchecked2 = unchecked.copy()\n",
    "\n",
    "old_checked_csv = \"../CSVfiles/catalog_unique.csv\"\n",
    "old_checked_cat = pd.read_csv(old_checked_csv)\n",
    "checked = fix_df(old_checked_cat)\n",
    "checked.head()\n",
    "checked2 = checked[['path', 'quality','subclass','D', 'R',\n",
    "       'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked', 'split',\n",
    "       'delete', 'ignore']]\n",
    "\n",
    "# MERGE\n",
    "unchecked2.update(checked2)\n",
    "\n",
    "# WRITE\n",
    "if len(unchecked)==len(unchecked2):    \n",
    "    df2csv_without_index(unchecked2, '11_merged_catalog.csv')\n",
    "    # manually copy this to ~/DATA/MVO/MachineLearning/SEISAN_DB/original/merged_catalog.csv\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_2 = unchecked2[unchecked2['num_traces']>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171622"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(more_than_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213206"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unchecked2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(more_than_2['checked']==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
