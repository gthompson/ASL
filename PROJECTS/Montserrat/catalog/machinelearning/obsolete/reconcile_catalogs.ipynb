{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge catalogs\n",
    "Reconcile full catalog on hal/newton in Fall 2021 with the incomplete but partially reclassified catalog from my laptop whilst in Paris in July 2021\n",
    "Need to reconcile reawav_MVOE_all.csv (concatenated reawav_MVOE_YYYYMM.csv) on hal9000 against catalog_unique.csv which came from processing in Paris \n",
    "on my laptop.\n",
    "\n",
    "Need to merge the new_subclass, weight, checked, split, delete and ignore columns.\n",
    "Should probably match on the WAVfile path.\n",
    "Do I need to merge D, R, r, e, l, h and t columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Concatenate the catalog YYYYMM CSV files into original master catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def subset_columns(df):\n",
    "    good_columns = []\n",
    "    for thiscol in df.columns:\n",
    "        if not 'ntitle' in thiscol:\n",
    "            if not 'Unname' in thiscol:\n",
    "                if not thiscol=='index':\n",
    "                    if not 'level_0' in thiscol:\n",
    "                        good_columns.append(thiscol)\n",
    "    df2 = df[good_columns] # subset to correct columns   \n",
    "    #df2.set_index('path', inplace=True)\n",
    "    #df2.sort_index(inplace=True)     \n",
    "    return df2\n",
    "\n",
    "def df2csv_without_index(df, csvfile):\n",
    "    #df = df.reset_index()  \n",
    "    #print(df.head())\n",
    "    print(df.columns)\n",
    "    df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    df.to_csv(csvfile, index=False)\n",
    "\n",
    "def _df2file_without_index(df, catfile, indexcol=None):\n",
    "    df = df.reset_index()  \n",
    "    if indexcol:\n",
    "        if not indexcol in df.columns:\n",
    "            df.rename(columns = {'index':indexcol})\n",
    "    df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "    if catfile[-3:]=='csv':\n",
    "        df.to_csv(catfile, index=False)\n",
    "    if catfile[-3:]=='pkl':\n",
    "        df.to_pickle(catalog_pickle_file)  \n",
    "    \n",
    "def number_of_checked_events(df):\n",
    "    df2 = df[df['checked']==True]\n",
    "    return len(df2.index)\n",
    "\n",
    "def build_master_event_catalog(pandaSeisDBDir, SEISAN_DB, catalogfile, subclasses_for_ML, max_duration = 300):\n",
    "\n",
    "    concatfile = 'catalog_all.csv'\n",
    "    if os.path.exists('catalog_all.csv'):\n",
    "        dfall = pd.read_csv(concatfile)\n",
    "    else:\n",
    "    \n",
    "        # load all the year/month CSV files\n",
    "        csvfiles = glob(os.path.join(pandaSeisDBDir, 'catalog_%s[12][0-9][0-9][0-9][0-1][0-9].csv' % SEISAN_DB))\n",
    "        frames = []\n",
    "        if len(csvfiles)==0:\n",
    "            print('No *.csv files found. Cannot proceed')\n",
    "            exit()\n",
    "        for csvfile in csvfiles:\n",
    "            df = pd.read_csv(csvfile)\n",
    "            frames.append(df) \n",
    "        dfall = pd.concat(frames, sort=True)\n",
    "        _df2file_without_index(dfall.copy(), concatfile)\n",
    "        \n",
    "    print(dfall.columns)\n",
    "\n",
    "    # replace loop above\n",
    "    for mainclass in ['R', 'D']:\n",
    "        dfall.loc[dfall['mainclass'] == mainclass, 'subclass'] = mainclass\n",
    "    \n",
    "    # Drop the mainclass column, as it is now superfluous.\n",
    "    dfall.drop(columns=['mainclass'], inplace=True)\n",
    "    \n",
    "    # Add columns to assign a percentage for each subclass\n",
    "    for subclass in subclasses_for_ML:\n",
    "        dfall[subclass] = 0\n",
    "    \n",
    "    # But set column for actual subclass to 100%  \n",
    "    for subclass in subclasses_for_ML:\n",
    "        dfall.loc[dfall['subclass'] == subclass, subclass] = 100\n",
    "        \n",
    "    # Add a new_subclass column\n",
    "    dfall['new_subclass'] = dfall['subclass']\n",
    "\n",
    "    # Add weight column. I will give really clear events higher weight when I process them\n",
    "    dfall['weight']=3 # weight for events I have not visually checked\n",
    "    \n",
    "    # Add column that records if event is checked\n",
    "    dfall['checked']=False\n",
    "    \n",
    "    # Add column that records if event is marked for splitting\n",
    "    dfall['split']=False    \n",
    "    \n",
    "    # Add column that records if event is marked for deletion\n",
    "    dfall['delete']=False\n",
    "    \n",
    "    # Add column that records if event should be ignored\n",
    "    # Ignore any events longer than 1-minute, as they are likely to contain multiple events \n",
    "    # or just be unhelpful for classifying short signals which are more common\n",
    "    # SCAFFOLD - the twin column no longer seems to exist\n",
    "    #dfall['ignore'] = dfall['twin']>max_duration\n",
    "    dfall['ignore'] = False\n",
    "    \n",
    "    # Now we have a catalog dataframe we can work with. Let's save this.\n",
    "    #dfall2 = dfall.reset_index()    \n",
    "    #dfall2.to_csv(catalogfile)\n",
    "    _df2file_without_index(dfall.copy(), catalogfile)\n",
    "    \n",
    "    return dfall\n",
    "\n",
    "def summarize_df(df):\n",
    "    print('Events: %d. Checked: %d ' % (len(df.index), number_of_checked_events(df)) )\n",
    "    print(df.columns)\n",
    "    dfhead = df.head()\n",
    "    print(dfhead[['path','DSN_wavfile']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 231951. Checked: 0 \n",
      "Index(['index', 'ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile',\n",
      "       'Eseismic', 'Fs', 'R', 'bandratio_[0.8_4.0_16.0]',\n",
      "       'bandratio_[1.0_6.0_11.0]', 'bw_max', 'bw_min', 'calib',\n",
      "       'corrected_ASN_mseed', 'corrected_DSN_mseed', 'day', 'elev', 'energy',\n",
      "       'filetime', 'hour', 'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF',\n",
      "       'minute', 'month', 'noise_level', 'num_gaps', 'num_traces', 'path',\n",
      "       'peakA', 'peakF', 'peakamp', 'peaktime', 'percent_availability',\n",
      "       'quality', 'sample_lower_quartile', 'sample_max', 'sample_mean',\n",
      "       'sample_median', 'sample_min', 'sample_rms', 'sample_stdev',\n",
      "       'sample_upper_quartile', 'second', 'sfile', 'signal_level', 'skewness',\n",
      "       'snr', 'subclass', 'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't',\n",
      "       'new_subclass', 'weight', 'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "                        path                DSN_wavfile\n",
      "0  9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1\n",
      "1  9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1\n",
      "2  9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1\n",
      "3  9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1\n",
      "4  9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO') # e.g. /home/user/seismo\n",
    "pandaSeisDir = os.path.join(SEISAN_DATA, 'miniseed_c') # e.g. /home/user/seismo/pandaSeis\n",
    "SEISAN_DB = 'MVOE_' # e.g. the seisan database name (e.g. MVOE_) under /home/user/seismo/WAV and /home/user/seismo/REA\n",
    "pandaSeisDBDir = os.path.join(pandaSeisDir, SEISAN_DB) # e.g. /home/user/seismo/pandaSeis/MVOE_\n",
    "AAA_DATA_DIR = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB) # e.g. /home/user/seismo/MachineLearning/MVOE_\n",
    "master_event_catalog_original = os.path.join(AAA_DATA_DIR, 'original', '%s11_master_catalog_rebuilt.csv' % SEISAN_DB)\n",
    "subclasses_for_ML = ['D', 'R', 'r', 'e', 'l', 'h', 't'] # subclasses allowed for Machine Learning # add g here?\n",
    "\n",
    "if os.path.exists(master_event_catalog_original):\n",
    "    dfall = pd.read_csv(master_event_catalog_original)\n",
    "else:\n",
    "    dfall = build_master_event_catalog(pandaSeisDBDir, SEISAN_DB, master_event_catalog_original, subclasses_for_ML)\n",
    "\n",
    "summarize_df(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 231951. Checked: 0 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "                        path                DSN_wavfile\n",
      "0  9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1\n",
      "1  9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1\n",
      "2  9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1\n",
      "3  9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1\n",
      "4  9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1\n"
     ]
    }
   ],
   "source": [
    "# ensure we always have the same index and columns\n",
    "dfall2 = subset_columns(dfall)\n",
    "summarize_df(dfall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove any events without a miniseed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 209135. Checked: 0 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "                        path                DSN_wavfile\n",
      "0  9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1\n",
      "1  9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1\n",
      "2  9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1\n",
      "3  9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1\n",
      "4  9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1\n"
     ]
    }
   ],
   "source": [
    "miniseed_cat = dfall2[dfall2['corrected_DSN_mseed'].isnull()==False]\n",
    "summarize_df(miniseed_cat)\n",
    "N_miniseed_cat = number_of_checked_events(miniseed_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Examine the catalog processed in July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'R', 'checked', 'delete', 'e', 'h', 'ignore', 'l', 'new_subclass', 'path', 'quality', 'r', 'split', 'subclass', 't', 'weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "some_checked_csv = \"../CSVfiles/catalog_unique.csv\"\n",
    "some_checked_cat = pd.read_csv(some_checked_csv)\n",
    "checked_cat = some_checked_cat[some_checked_cat['checked']==True]\n",
    "checked_cat = checked_cat[['path', 'quality','subclass','D', 'R',\n",
    "       'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked', 'split',\n",
    "       'delete', 'ignore']]\n",
    "#checked_cat.rename(columns={'path':'DSN_wavfile'}, inplace=True)\n",
    "N_checked_cat = number_of_checked_events(checked_cat)\n",
    "print(sorted(checked_cat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/original/MVOE_11_master_catalog_rebuilt.csv has 0 checked events\n",
      "../CSVfiles/catalog_unique.csv has 584 checked events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore', 'path'],\n",
      "      dtype='object')\n",
      "Events: 209092. Checked: 584 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore', 'path'],\n",
      "      dtype='object')\n",
      "                                                path  \\\n",
      "path                                                   \n",
      "9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1   \n",
      "9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1   \n",
      "9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1   \n",
      "9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1   \n",
      "9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1   \n",
      "\n",
      "                                         DSN_wavfile  \n",
      "path                                                  \n",
      "9801-01-0002-04S.MVO_18_1  9801-01-0002-04S.MVO_18_1  \n",
      "9801-01-0104-32S.MVO_18_1  9801-01-0104-32S.MVO_18_1  \n",
      "9801-01-0121-09S.MVO_18_1  9801-01-0121-09S.MVO_18_1  \n",
      "9801-01-0200-27S.MVO_18_1  9801-01-0200-27S.MVO_18_1  \n",
      "9801-01-0221-36S.MVO_18_1  9801-01-0221-36S.MVO_18_1  \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore', 'path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('%s has %d checked events' % (master_event_catalog_original, N_miniseed_cat) )\n",
    "print('%s has %d checked events' % (some_checked_csv, N_checked_cat) )\n",
    "\n",
    "# RESET INDEXES\n",
    "set_index_to_path = True\n",
    "if set_index_to_path:\n",
    "    if 'path' in miniseed_cat.columns:\n",
    "        miniseed_cat.set_index('path', inplace=True)\n",
    "        #miniseed_cat.sort_index(inplace=True)\n",
    "    if 'path' in checked_cat.columns:\n",
    "        checked_cat.set_index('path', inplace=True)\n",
    "        #checked_cat.sort_index(inplace=True)\n",
    "\n",
    "def mergeGT(miniseed, checked):\n",
    "    frames = []\n",
    "    for i2, row in checked.iterrows():\n",
    "        i2base = os.path.basename(i2)\n",
    "        subset_df = miniseed[miniseed.index == i2base]\n",
    "        if len(subset_df.index)==1:\n",
    "            for col in checked.columns:\n",
    "                subset_df.loc[i2base, col] = row[col]\n",
    "            frames.append(subset_df)   \n",
    "    newdf = pd.concat(frames)\n",
    "    newdf['path'] = newdf.index\n",
    "    combineddf = pd.concat([miniseed, newdf])\n",
    "    combineddf['path'] = combineddf.index\n",
    "    mergeddf = combineddf.drop_duplicates(subset=['path'], keep='last')\n",
    "    return mergeddf\n",
    "merged_cat = mergeGT(miniseed_cat, checked_cat)\n",
    "\n",
    "print(merged_cat.columns)\n",
    "summarize_df(merged_cat)\n",
    "N_merged_cat = number_of_checked_events(merged_cat)\n",
    "df2csv_without_index(merged_cat, 'merged_cat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong with df.update\n",
      "209135 209092\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# WRITE\n",
    "if len(miniseed_cat)==len(merged_cat): \n",
    "    if len(merged_cat.index)>=len(checked_cat.index) and N_merged_cat>N_unchecked_cat:\n",
    "        print('Merging worked. Saving')\n",
    "        df2csv_without_index(merged_cat, 'merged_cat.csv')\n",
    "        #df2csv_without_index(unchecked, '/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/labelling/11_merged_catalog_4.csv')\n",
    "        # manually copy this to ~/DATA/MVO/MachineLearning/SEISAN_DB/original/merged_catalog.csv\n",
    "    else:\n",
    "        print('Merging failed - checked events missing')\n",
    "else:\n",
    "    print('Something went wrong with df.update')\n",
    "    print(len(miniseed_cat), len(merged_cat))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/original/MVOE_11_master_catalog_rebuilt.csv has 0 checked events\n",
      "../CSVfiles/catalog_unique.csv has 584 checked events\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-f245bb917b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m        \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'new_subclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checked'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m        'delete', 'ignore']:\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmerged_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecked_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'path'"
     ]
    }
   ],
   "source": [
    "#merged_cat = miniseed_cat.merge(checked_cat, how='left', on='path')\n",
    "merged_cat = miniseed_cat.copy()\n",
    "for col in ['quality','subclass','D', 'R',\n",
    "       'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked', 'split',\n",
    "       'delete', 'ignore']:\n",
    "    merged_cat = merged_cat['path'].map(checked_cat.set_index('path')[col]).fillna(merged_cat[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "Index(['path', 'quality', 'subclass', 'D', 'R', 'r', 'e', 'l', 'h', 't',\n",
      "       'new_subclass', 'weight', 'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R_x', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality_x',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass_x',\n",
      "       'twin', 'year', 'D_x', 'r_x', 'e_x', 'l_x', 'h_x', 't_x',\n",
      "       'new_subclass_x', 'weight_x', 'checked_x', 'split_x', 'delete_x',\n",
      "       'ignore_x', 'quality_y', 'subclass_y', 'D_y', 'R_y', 'r_y', 'e_y',\n",
      "       'l_y', 'h_y', 't_y', 'new_subclass_y', 'weight_y', 'checked_y',\n",
      "       'split_y', 'delete_y', 'ignore_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(miniseed_cat.columns)\n",
    "print(checked_cat.columns)\n",
    "print(merged_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'checked'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'checked'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6e145e723524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#merged_cat = miniseed_cat.copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#merged_cat.update(checked_cat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mN_merged_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_checked_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'merged_cat has %d checked events'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN_merged_cat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-a9a88869af2a>\u001b[0m in \u001b[0;36mnumber_of_checked_events\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnumber_of_checked_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'checked'"
     ]
    }
   ],
   "source": [
    "# MERGE\n",
    "print('merging')\n",
    "#merged_cat = miniseed_cat.copy()\n",
    "#merged_cat.update(checked_cat)\n",
    "N_merged_cat = number_of_checked_events(merged_cat)\n",
    "print('merged_cat has %d checked events' % (N_merged_cat) )\n",
    "\n",
    "# WRITE\n",
    "if len(miniseed_cat)==len(merged_cat): \n",
    "    if len(merged_cat.index)>=len(checked_cat.index) and N_merged_cat>N_unchecked_cat:\n",
    "        print('Merging worked. Saving')\n",
    "        df2csv_without_index(merged_cat, 'merged_cat.csv')\n",
    "        #df2csv_without_index(unchecked, '/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/labelling/11_merged_catalog_4.csv')\n",
    "        # manually copy this to ~/DATA/MVO/MachineLearning/SEISAN_DB/original/merged_catalog.csv\n",
    "    else:\n",
    "        print('Merging failed - checked events missing')\n",
    "else:\n",
    "    print('Something went wrong with df.update')\n",
    "    print(len(miniseed_cat), len(merged_cat))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209135 209135\n"
     ]
    }
   ],
   "source": [
    "print(len(miniseed_cat), len(merged_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events: 0. Checked: 0 \n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'peakA', 'peakF', 'peakamp',\n",
      "       'peaktime', 'percent_availability', 'quality', 'sample_lower_quartile',\n",
      "       'sample_max', 'sample_mean', 'sample_median', 'sample_min',\n",
      "       'sample_rms', 'sample_stdev', 'sample_upper_quartile', 'second',\n",
      "       'sfile', 'signal_level', 'skewness', 'snr', 'subclass', 'twin', 'year',\n",
      "       'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked',\n",
      "       'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['path'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-56d3ae87902e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckeddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummarize_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckeddf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-a9a88869af2a>\u001b[0m in \u001b[0;36msummarize_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mdfhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DSN_wavfile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/AAA/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['path'] not in index\""
     ]
    }
   ],
   "source": [
    "checkeddf = merged_cat[merged_cat['checked']==True]\n",
    "summarize_df(checkeddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/shareddrive/thompsong/MachineLearning/MVOE_/original/MVOE_11_master_catalog_original2.csv has 0 checked events\n",
      "../CSVfiles/catalog_unique.csv has 584 checked events\n",
      "merging\n",
      "merged_cat has 571 checked events\n",
      "Merging worked. Saving\n",
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "#full_unchecked_csv = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB, 'labelling', '%scatalog.csv' % SEISAN_DB)\n",
    "full_unchecked_csv = os.path.join('/Volumes/shareddrive/thompsong', 'MachineLearning', \\\n",
    "                                  SEISAN_DB, 'labelling', '%s11_master_catalog.csv' % SEISAN_DB)\n",
    "\n",
    "\n",
    "full_unchecked_cat = pd.read_csv(full_unchecked_csv)    \n",
    "unchecked = fix_df(full_unchecked_cat)\n",
    "unchecked2 = unchecked.copy()\n",
    "\"\"\"\n",
    "\n",
    "full_catalog_csv = '/Volumes/shareddrive/thompsong/MachineLearning/MVOE_/original/MVOE_11_master_catalog_original2.csv'\n",
    "full_catalog_df = pd.read_csv(full_catalog_csv)\n",
    "dsn_exists_df = full_catalog_df[full_catalog_df['DSN_exists']==True]\n",
    "miniseed_c_exists_df = dsn_exists_df[dsn_exists_df['corrected_DSN_mseed'].isnull()==False]\n",
    "unchecked_cat = fix_df(miniseed_c_exists_df)\n",
    "N_unchecked_cat = number_of_checked_events(unchecked_cat)\n",
    "\n",
    "some_checked_csv = \"../CSVfiles/catalog_unique.csv\"\n",
    "some_checked_cat = pd.read_csv(some_checked_csv)\n",
    "some_checked_cat = fix_df(some_checked_cat)\n",
    "checked_cat = some_checked_cat[some_checked_cat['checked']==True]\n",
    "checked_cat = checked_cat[['path', 'quality','subclass','D', 'R',\n",
    "       'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight', 'checked', 'split',\n",
    "       'delete', 'ignore']]\n",
    "checked_cat.rename(columns={'path':'DSN_wavfile'}, inplace=True)\n",
    "N_checked_cat = number_of_checked_events(checked_cat)\n",
    "\n",
    "print('%s has %d checked events' % (full_catalog_csv, N_unchecked_cat) )\n",
    "print('%s has %d checked events' % (some_checked_csv, N_checked_cat) )\n",
    "\n",
    "# MERGE\n",
    "print('merging')\n",
    "merged_cat = unchecked_cat.copy()\n",
    "merged_cat.update(checked_cat2)\n",
    "N_merged_cat = number_of_checked_events(merged_cat)\n",
    "print('merged_cat has %d checked events' % (N_merged_cat) )\n",
    "\n",
    "# WRITE\n",
    "if len(unchecked_cat)==len(merged_cat): \n",
    "    if len(merged_cat.index)>=len(checked_cat.index) and N_merged_cat>N_unchecked_cat:\n",
    "        print('Merging worked. Saving')\n",
    "        df2csv_without_index(unchecked, '/Users/thompsong/DATA/MVO/MachineLearning/MVOE_/labelling/11_merged_catalog_4.csv')\n",
    "        # manually copy this to ~/DATA/MVO/MachineLearning/SEISAN_DB/original/merged_catalog.csv\n",
    "    else:\n",
    "        print('Merging failed - checked events missing')\n",
    "else:\n",
    "    print('Something went wrong with df.update')\n",
    "    print(len(unchecked_cat), len(merged_cat))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ASN_exists', 'ASN_wavfile', 'DSN_exists', 'DSN_wavfile', 'Eseismic',\n",
      "       'Fs', 'R', 'bandratio_[0.8_4.0_16.0]', 'bandratio_[1.0_6.0_11.0]',\n",
      "       'bw_max', 'bw_min', 'calib', 'corrected_ASN_mseed',\n",
      "       'corrected_DSN_mseed', 'day', 'elev', 'energy', 'filetime', 'hour',\n",
      "       'kurtosis', 'lat', 'lon', 'magA', 'magE', 'medianF', 'minute', 'month',\n",
      "       'noise_level', 'num_gaps', 'num_traces', 'path', 'peakA', 'peakF',\n",
      "       'peakamp', 'peaktime', 'percent_availability', 'quality',\n",
      "       'sample_lower_quartile', 'sample_max', 'sample_mean', 'sample_median',\n",
      "       'sample_min', 'sample_rms', 'sample_stdev', 'sample_upper_quartile',\n",
      "       'second', 'sfile', 'signal_level', 'skewness', 'snr', 'subclass',\n",
      "       'twin', 'year', 'D', 'r', 'e', 'l', 'h', 't', 'new_subclass', 'weight',\n",
      "       'checked', 'split', 'delete', 'ignore'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_2 = unchecked2[unchecked2['num_traces']>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190199"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(more_than_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213206"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unchecked2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(more_than_2['checked']==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thompsong/miniconda3/envs/AAA/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (0,2,14,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dftest = pd.read_csv('11_merged_catalog_3.csv')\n",
    "print(len(dftest.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of checked events = 1021\n"
     ]
    }
   ],
   "source": [
    "def number_of_checked_events(df):\n",
    "    df2 = df[df['checked']==True]\n",
    "    print('Number of checked events = %d' % len(df2.index))\n",
    "    \n",
    "number_of_checked_events(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup main directory paths & input/output files\n",
    "SEISAN_DATA = os.path.join( os.getenv('HOME'),'DATA','MVO') # e.g. /home/user/seismo\n",
    "#pandaSeisDir = os.path.join(SEISAN_DATA, 'pandaSeis') # e.g. /home/user/seismo/pandaSeis\n",
    "pandaSeisDir = os.path.join(SEISAN_DATA, 'miniseed_c') # e.g. /home/user/seismo/pandaSeis\n",
    "SEISAN_DB = 'MVOE_' # e.g. the seisan database name (e.g. MVOE_) under /home/user/seismo/WAV and /home/user/seismo/REA\n",
    "pandaSeisDBDir = os.path.join(pandaSeisDir, SEISAN_DB) # e.g. /home/user/seismo/pandaSeis/MVOE_\n",
    "AAA_DATA_DIR = os.path.join(SEISAN_DATA, 'MachineLearning', SEISAN_DB) # e.g. /home/user/seismo/MachineLearning/MVOE_\n",
    "master_event_catalog = os.path.join(AAA_DATA_DIR, 'labelling', '%s11_master_catalog.csv' % SEISAN_DB)\n",
    "aaa_input_file = os.path.join(AAA_DATA_DIR, 'runAAA', '%s11_labelled_events.csv' % SEISAN_DB) \n",
    "\n",
    "\n",
    "# read items from Seisan software setup\n",
    "volcanodefcsv = 'CSVfiles/volcano_def.csv'\n",
    "if not os.path.exists(volcanodefcsv):\n",
    "    print('%s not found. exiting' % volcanodefcsv)\n",
    "    exit()\n",
    "subclass_mapping = read_volcano_def(volcanodefcsv) # subclasses allowed for classification\n",
    "seisan_subclasses = subclass_mapping['subclass'].values.tolist() # append('g') as needed, it is not an allowed subclass\n",
    "#seisan_etypes = subclass_mapping['etype'].values.tolist()\n",
    "subclasses_for_ML = ['D', 'R', 'r', 'e', 'l', 'h', 't'] # subclasses allowed for Machine Learning\n",
    "station0hypfile = os.path.join(SEISAN_DATA, 'DAT', 'STATION0_MVO.HYP')\n",
    "\n",
    "# Load a previously created master event catalog from AAA_DATA_DIR - or create a new one from pandaSeisDBDir\n",
    "\"\"\"\n",
    "if os.path.exists(catalog_pickle_file):\n",
    "    try:\n",
    "        dfall = pd.read_pickle(catalog_pickle_file)   \n",
    "    except:\n",
    "        dfall = pd.read_csv(master_event_catalog) # how do i ignore the index?\n",
    "elif os.path.exists(master_event_catalog): # load the one that exists from AAA_DATA_DIR, and trim the columns\n",
    "\"\"\"\n",
    "if os.path.exists(master_event_catalog):\n",
    "    dfall = pd.read_csv(master_event_catalog) # how do i ignore the index?\n",
    "else: # create one \n",
    "    print('%s does not exist, will try to create a new master event catalog from pandaSeisDBDir' % master_event_catalog)\n",
    "    dfall = build_master_event_catalog(pandaSeisDBDir, SEISAN_DB, master_event_catalog_original, subclasses_for_ML)\n",
    "    if os.path.exists(master_event_catalog_original):\n",
    "        print(master_event_catalog_original, ' created')\n",
    "        print('Copying to %s' % master_event_catalog)\n",
    "        os.system(\"cp %s %s\" % (master_event_catalog_original, master_event_catalog))\n",
    "    else:\n",
    "        print('Unable to make ',master_event_catalog_original, '. Quitting.')\n",
    "        exit()\n",
    "   \n",
    "number_of_checked_events(dfall)\n",
    " \n",
    "# ensure we always have the same index and columns\n",
    "good_columns = []\n",
    "for thiscol in dfall.columns:\n",
    "    if 'ntitle' not in thiscol:\n",
    "        good_columns.append(thiscol)\n",
    "dfall = dfall[good_columns] # subset to correct columns\n",
    "dfall.set_index('path', inplace=True) # try this\n",
    "dfall.sort_index(inplace=True)   \n",
    "    \n",
    "    \n",
    "number_of_checked_events(dfall)\n",
    "# LOOPING BEGINS HERE ####################################\n",
    "\n",
    "iterate_again = False # changed this back to do the loop\n",
    "changes_made = True\n",
    "while iterate_again:\n",
    "\n",
    "    # get/update the fingerprints of each event class\n",
    "    #fingerprints = get_weighted_fingerprints(dfall, subclasses_for_ML, N=100, exclude_checked=False)\n",
    "    fingerprints = get_fingerprints(dfall, subclasses_for_ML, N=100, exclude_checked=False)\n",
    "    save_fingerprints(fingerprints, subclasses_for_ML)\n",
    "    \n",
    "    # get index (path) of next event\n",
    "    nextwav = select_next_event(dfall, subclasses_for_ML)\n",
    "    print('Selected ',nextwav)\n",
    "    \n",
    "    # manually QC the next event. each time we choose the class with least checked examples\n",
    "    bool_quit = qc_event(dfall, nextwav, subclasses_for_ML, seisan_subclasses, fingerprints, pandaSeisDBDir, station0hypfile)\n",
    "    if bool_quit:\n",
    "        iterate_again=False\n",
    "    else: # changes made\n",
    "        changes_made = True\n",
    "        _df2file_without_index(dfall.copy(), catalog_pickle_file, 'path')     \n",
    "\n",
    "# LOOPING ENDS HERE ######################################        \n",
    "\n",
    "\n",
    "# Save\n",
    "if changes_made:\n",
    "    \n",
    "    print('Quitting. Saving changes.')\n",
    "    \n",
    "    print('Updating %s' % master_event_catalog)\n",
    "    _df2file_without_index(dfall, master_event_catalog, 'path')\n",
    "\n",
    "    # remove events we marked for deletion, splitting or to ignore\n",
    "    dfsubset = remove_marked_events(dfall)\n",
    "    number_of_checked_events(dfsubset)\n",
    "\n",
    "    #to_AAA(dfsubset, subclasses_for_ML, aaa_infile, SEISAN_DATA, ignore_extra_columns=False)\n",
    "    print('Updating %s' % aaa_input_file)\n",
    "    to_AAA(dfsubset, subclasses_for_ML, aaa_input_file, ignore_extra_columns=True)\n",
    "\n",
    "    report_checked_events(dfall, subclasses_for_ML)\n",
    "else:\n",
    "    print('Quitting. No changes made.')\n",
    "print('The end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
